{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#MNIST 데이터를 이용해 손글씨 숫자 이미지를 분류하는 간단한 CNN 구현"
      ],
      "metadata": {
        "id": "EbfqNOlCMl3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1TJr2Q5lKio2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 모듈 불러오기"
      ],
      "metadata": {
        "id": "8qfP2ttFMr1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적으로 프로젝트 상단에 작성"
      ],
      "metadata": {
        "id": "mgM6A-_uOVnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch 라이브러리\n",
        "import torch\n",
        "\n",
        "#딥러닝 네트워크의 기본 구성요소를 포함한 torch.nn모듈\n",
        "import torch.nn as nn\n",
        "\n",
        "#딥러닝에 자주 사용되는 함수를 포함한 torch.nn.functional 모듈\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#가중치 추정에 필요한 최적화 알고리즘을 포함한 torch.optim 모듈\n",
        "import torch.optim as optim\n",
        "\n",
        "#딥러닝에 자주 사용되는 데이터셋과 모델 구조 및 이미지 변환 기술을 포함한 torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "#시각화\n",
        "from matplotlib import pyplot as plt\n",
        "#주피터 노트북에서, 브라우저에서 바로 그림을 보려면 실행해야함\n",
        "%matplotlib inline "
      ],
      "metadata": {
        "id": "X7bEv2ErMs92"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dKdDyrbKOYEG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 분석환경 세팅"
      ],
      "metadata": {
        "id": "3gSTJ5nkOXtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터에 어떤 장비를 사용할지 지정해야하므로, device를 미리 작성하는 것이 유용"
      ],
      "metadata": {
        "id": "fljYSCzRPHrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cuda로 gpu를 사용할 수 있으면, is_cuda=True, 사용할 수 없다면 is_cuda=False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "#is_cuda에 따라 device = cuda or cpu\n",
        "device = torch.device('cuda' if is_cuda else 'cpu')\n",
        "\n",
        "print('Current cuda device is', device)\n",
        "#cpu 사용시, Current cuda device is cpu\n",
        "#gpu 사용시, Current cuda device is cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyUUDnW3OYj9",
        "outputId": "879fe72a-9556-47e4-f015-07e9847443fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current cuda device is cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EpqtTKA9Olrx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. hyperparameter 지정"
      ],
      "metadata": {
        "id": "nMpWebJKPVaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "필요한 hyperparameter를 미리 지정"
      ],
      "metadata": {
        "id": "-JTImi__Prpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 가중치를 한번 업데이트 시킬때 사용되는 샘플 단위 개수(미니배치 사이즈)\n",
        "batch_size = 50\n",
        "\n",
        "#학습 데이터를 모두 사용하여 1번 학습하는 기본 단위 횟수 = 1epoch\n",
        "epoch_num = 15\n",
        "\n",
        "#가중치 업데이트의 정도\n",
        "learning_rate = 0.0001"
      ],
      "metadata": {
        "id": "iJNDHVQrPXA8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "24az0G_zQmpj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. MNIST 데이터 불러오기"
      ],
      "metadata": {
        "id": "cH1r7kYXQmXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pytorch 모듈안에 내장되어 있어서 쉽게 불러올 수 있음"
      ],
      "metadata": {
        "id": "8EyzOkBEQq11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#root = MNIST 데이터를 저장할 위치\n",
        "\n",
        "#train = True이면 학습데이터, False이면 테스트데이터\n",
        "\n",
        "#download = True이면, 다운받아서 root에 지정한 폴더에 저장, False이면 다운받지 않는다\n",
        "\n",
        "#transform = MNIST 데이터를 저장과 동시에 지정한 함수로 전처리\n",
        "#transforms.ToTensor()는 이미지를 tensor로 바꿔준다.\n",
        "\n",
        "train_data = datasets.MNIST(root = './data', train=True, download=True, transform = transforms.ToTensor())\n",
        "test_data = datasets.MNIST(root = './data', train=False, transform = transforms.ToTensor())\n",
        "\n",
        "#len()함수로 데이터 개수 확인\n",
        "print('number of training data: ', len(train_data))\n",
        "print('number of test data: ', len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7EoGpl4Qn_K",
        "outputId": "d0ddf4c1-d54d-49f4-a084-ccee009a3b7a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training data:  60000\n",
            "number of test data:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NzHzQM1KRChH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 데이터 확인"
      ],
      "metadata": {
        "id": "5Z0rWl8hSYuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터의 일부를 시각화를 통해 확인"
      ],
      "metadata": {
        "id": "76VrC85ISdhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#0번째 학습데이터와 정답을 저장\n",
        "image, label = train_data[0]\n",
        "\n",
        "print(image.shape)\n",
        "#MNIST는 3차원 텐서로 [1,28,28]\n",
        "\n",
        "#3차원 텐서를 2차원으로 줄이기 위해 image.squeeze()로 [28,28]로 바꿔줌\n",
        "\n",
        "print(image.squeeze().shape)\n",
        "\n",
        "#image tensor를 numpy array로 바꿔줘야 확인 가능\n",
        "plt.imshow(image.squeeze().numpy(), cmap = 'gray')\n",
        "\n",
        "plt.title('label : %s' %label)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "kOaHTQadSZAh",
        "outputId": "73fce762-c901-4aff-82d5-8a911df47501"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pB17zHgJSqor"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 미니 배치 구성"
      ],
      "metadata": {
        "id": "0foc0RqpmC8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "미리 지정한 batch_size로 미니 배치를 구성"
      ],
      "metadata": {
        "id": "x8UVIuOZnMPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.utils.data.DataLoader()은 손쉽게 배치를 구성하고, 학습 과정을 반복 시행할때마다 미니 배치를 하나씩 불러온다\n",
        "\n",
        "#dataset = 미니 배치로 구성할 데이터\n",
        "#batch_size = 미니 배치의 사이즈 = 50\n",
        "#shuffle = 데이터의 순서를 랜덤으로 섞어서 미니 배치를 구성할지 여부\n",
        "#시계열 데이터가 아니라면, 딥러닝이 데이터의 순서에 대해 학습하지 못하도록 랜덤으로 섞어주는 것을 권장\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "first_batch = train_loader.__iter__().__next__()\n",
        "\n",
        "print('{:15s} | {:<25s} | {}'.format('name','type','size'))\n",
        "print('{:15s} | {:<25s} | {}'.format('Num of Batch','',len(train_loader)))\n",
        "print('{:15s} | {:<25s} | {}'.format('first_batch',str(type(first_batch)),len(first_batch)))\n",
        "print('{:15s} | {:<25s} | {}'.format('first_batch[0]',str(type(first_batch[0])),first_batch[0].shape))\n",
        "print('{:15s} | {:<25s} | {}'.format('first_batch[1]',str(type(first_batch[1])), first_batch[1].shape))\n",
        "\n",
        "#1200개의 미니 배치 생성\n",
        "#60000개의 train데이터에서, 배치 사이즈로 50을 설정했으니, 50*1200 = 60000\n",
        "#first_batch[0]의 size가 [50,1,28,28]은 [batch_size, channel, width, height]\n",
        "#데이터 1개가 [1,28,28]인데, 50개 쌓여서 [50,1,28,28]\n",
        "#first_batch[1]에는 50개의 각 데이터마다 정답이 있어서 size가 [50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1BRPozemDUc",
        "outputId": "a63cf1b3-513a-4acd-91a9-0a6ad5a37bb3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name            | type                      | size\n",
            "Num of Batch    |                           | 1200\n",
            "first_batch     | <class 'list'>            | 2\n",
            "first_batch[0]  | <class 'torch.Tensor'>    | torch.Size([50, 1, 28, 28])\n",
            "first_batch[1]  | <class 'torch.Tensor'>    | torch.Size([50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ITPejNqznGsB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. 모델 구축"
      ],
      "metadata": {
        "id": "nFGz3_Dk39Cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.Module은 pytorch 모델 클래스가 상속받는 모듈 클래스\n",
        "#__init__ 메소드와 forward 메소드를 반드시 설정해야함\n",
        "class CNN(nn.Module):\n",
        "    \n",
        "    #모델에 사용되는 layer들을 정의\n",
        "    def __init__(self):\n",
        "        \n",
        "        #nn.Module 클래스의 상속을 상속받는다.\n",
        "        super(CNN,self).__init__()\n",
        "\n",
        "        #in_channels, out_channels, kernel_size, stride\n",
        "\n",
        "        #in_channels는 input tensor의 channel\n",
        "        #out_channels는 output tensor의 channel\n",
        "        #kernel_size는 kernel의 크기, 값 하나로 주면 가로 세로가 같은 kernel, tuple로 주면 세로*가로 형태\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1)\n",
        "\n",
        "        #conv1을 통과한 tensor의 channel이 32이고 이것이 conv2를 통과하므로..\n",
        "        #conv2의 in_channels는 32여야함\n",
        "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1)\n",
        "\n",
        "        #dropout layer 정의\n",
        "\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "\n",
        "        #fullyt connected layer 정의\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features = 9216, out_features = 128)\n",
        "\n",
        "        #마지막 layer의 out_features는 MNIST의 분류 클래스가 0~9로 10개이므로.. 10으로\n",
        "        #당연히 in_features는 이전 fc1의 out_features와 같게\n",
        "        self.fc2 = nn.Linear(in_features = 128, out_features = 10)\n",
        "    \n",
        "    #feed forward 연산을 수행하는 forward 메소드 정의\n",
        "\n",
        "    #layer를 통과시키고\n",
        "    #중간중간에 활성함수를 넣고\n",
        "    #중간중간에 dropout 등을 넣어준다\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "\n",
        "        #activation\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "\n",
        "        x = F.relu(x)\n",
        "\n",
        "        #max_pooling\n",
        "        x = F.max_pool2d(x,2)\n",
        "\n",
        "        #dropout\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        #flatten\n",
        "        x = torch.flatten(x,1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        #확률 벡터로 바꾸기 위해 softmax를 적용\n",
        "        #log softmax를 사용하면 연산속도를 높여줄 수 있음\n",
        "        output = F.log_softmax(x,dim=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CkkRB2B_3-EL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zg0bdxiqJwmJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. optimizer, loss function 정의"
      ],
      "metadata": {
        "id": "afb_hQX8IWRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN 클래스로 모델 인스턴스 생성\n",
        "#to(device)를 수행하면, 모델 인스턴스를 device에 올릴 수 있다\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "#optimizer 정의\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "#loss function\n",
        "#다중 클래스 분류 문제이므로, cross entropy 사용\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "GNcEHjy1IWFL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 확인\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB36wuT4JwJ0",
        "outputId": "aa0e7521-1343-434d-fed9-67ecdc4e6d19"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. 모델 학습"
      ],
      "metadata": {
        "id": "E31_0SSGJvum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimizer.zero_grad() > output = model(data) > loss = criterion(output,target) > loss.backward() > optimizer.step()"
      ],
      "metadata": {
        "id": "CUSD9fwvNWJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델을 학습 모드로 바꿔준다\n",
        "model.train()\n",
        "\n",
        "i = 0\n",
        "\n",
        "#epoch_num만큼 반복학습 수행\n",
        "for epoch in range(epoch_num):\n",
        "    \n",
        "    #각 epoch내에서 train_loader를 순회\n",
        "    for data,target in train_loader:\n",
        "        \n",
        "        #모델에 할당된 device에 data,target들도 할당해줘야함\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        #optimizer에 저장된 gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #모델에 data 통과시켜 output 계산\n",
        "        output = model(data)\n",
        "\n",
        "        #loss 계산\n",
        "        loss = criterion(output,target)\n",
        "\n",
        "        #gradient계산\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        #가중치 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        #학습이 잘 되고 있는지 1000번째 배치마다, loss가 어떻게 변하는지 확인\n",
        "        if i % 1000 == 0:\n",
        "            \n",
        "            print('Train Step: {}\\tLoss: {:.3f}'.format(i,loss.item()))\n",
        "        \n",
        "        i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fIy3fMQKK6c",
        "outputId": "fc93b9ab-28bf-4fda-be65-15a4ea75b694"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Step: 0\tLoss: 2.311\n",
            "Train Step: 1000\tLoss: 0.194\n",
            "Train Step: 2000\tLoss: 0.253\n",
            "Train Step: 3000\tLoss: 0.077\n",
            "Train Step: 4000\tLoss: 0.246\n",
            "Train Step: 5000\tLoss: 0.014\n",
            "Train Step: 6000\tLoss: 0.126\n",
            "Train Step: 7000\tLoss: 0.062\n",
            "Train Step: 8000\tLoss: 0.021\n",
            "Train Step: 9000\tLoss: 0.144\n",
            "Train Step: 10000\tLoss: 0.015\n",
            "Train Step: 11000\tLoss: 0.039\n",
            "Train Step: 12000\tLoss: 0.009\n",
            "Train Step: 13000\tLoss: 0.040\n",
            "Train Step: 14000\tLoss: 0.151\n",
            "Train Step: 15000\tLoss: 0.027\n",
            "Train Step: 16000\tLoss: 0.019\n",
            "Train Step: 17000\tLoss: 0.052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "StGTqUr1OeGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. 모델 평가"
      ],
      "metadata": {
        "id": "8HVLkWKAOeXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델을 평가모드로 전환\n",
        "#dropout, batchnormalization을 test 모드로 바꿔줌\n",
        "model.eval()\n",
        "\n",
        "correct = 0 #정답 개수\n",
        "\n",
        "#gradient를 계산하지 않도록 해준다.\n",
        "#계산속도 증가, 메모리 절약\n",
        "with torch.no_grad():\n",
        "    \n",
        "    #test_loader를 순회해서 배치와 label을 가져오고\n",
        "    for data, target in test_loader:\n",
        "        \n",
        "        #모델과 동일한 device에 할당\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        #output 계산\n",
        "        output = model(data)\n",
        "\n",
        "        #가장 확률이 높은 부분의 인덱스를 찾아 그것을 예측값 클래스로 전환\n",
        "\n",
        "        prediction = output.data.max(1)[1]\n",
        "\n",
        "        #prediction과 target값을 비교하여, correct에 더해준다\n",
        "        correct += prediction.eq(target.data).sum()\n",
        "\n",
        "#전체 테스트 데이터 개수 대비 맞춘 개수 비율 계산\n",
        "\n",
        "print('Test set: Accuracy: {:.2f}%'.format(100*correct/len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIgNYpsaOf2l",
        "outputId": "ece18476-402c-40cf-8303-5d6bb2a0c29c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Accuracy: 99.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7FdBr7OBR1-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}