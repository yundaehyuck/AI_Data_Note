{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2 : Segmentation"
      ],
      "metadata": {
        "id": "xLnnjR6rubjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 과제에서는, Assignment 1에서 classification 문제를 풀기 위해 구성했던 CNN 모델을 **segmentation 문제를 풀기 위한 모델**로 재구성해보는 과정을 진행합니다. 모델에서 layer들을 구성하는 모듈들이 동작하는 방식을 더 잘 이해하는 시간이 되셨으면 좋겠습니다."
      ],
      "metadata": {
        "id": "5NtlYhfSueZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note"
      ],
      "metadata": {
        "id": "0yU7RcTYuiQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note on copying Tensor\n",
        "\n",
        "You may use different methods for copying Tensor. Here, we list possible means you may use.\n",
        "\n",
        "(1) y = x.detach()    \n",
        "- This creates new Tensor that does not compute gradient from the original Tensor\n",
        "- You can modify such method **x.clone().detach().requires_grad_(True)** to indicate requires_grad option\n",
        "\n",
        "(2) y = x.data\n",
        "- x.data  used to get Tensor from Variable\n",
        "- **detach()** may be better, since Tensor copied from **.data** method even uses wrong gradient during update (while **detach()** outputs error on wrong gradients)\n",
        "\n",
        "(3) y = torch.empty_like(x).copy_(x)\n",
        "- This creates new Tensor that has the same content from the original Tensor\n",
        "\n",
        "(4) y = torch.tensor(x)\n",
        "\n",
        "(5) y = tensor.new_tensor(x)\n",
        "- You can indicates **require_grad** option with this method"
      ],
      "metadata": {
        "id": "0MiUo-Kyuk1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note on assigning weight\n",
        "\n",
        "You may use different methods for assigning weight from pre-defined Tensor. Here, we list possible means you may use.\n",
        "\n",
        "\n",
        "(1) layer_.weight = torch.nn.Parameter(tensor_)\n",
        "\n",
        "(2) layer_.wiehgt = torch.Tensor(tensor_)\n",
        "\t- You can use this methods during initionalization\n"
      ],
      "metadata": {
        "id": "-4Is0kZLuyjT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y0N-0l3ztOiD"
      },
      "outputs": [],
      "source": [
        "#drive mount & data, model move\n",
        "!cp ./drive/MyDrive/Assignment2_model_pretrained.pth ./model.pth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R ./drive/MyDrive/Assignment2_data ./data"
      ],
      "metadata": {
        "id": "eqeH8obPwgTL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P9bTC2Y5wkZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **VGG-11 Implementation**"
      ],
      "metadata": {
        "id": "aCqwQqp7xSZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert VGG-11 model for image classification into semantic segmentation. You will modify the last fc layer into 1x1 conv. layer. Recall that semantic segmentation can be considered of classification problem on each pixel of the input image data.\n",
        "\n",
        "Here, we defined backbone model that is commonly used for both classification and segmentation cases. Backbone of the model is composed of 5 blocks of convolutional layers (along with batch-normalization and pooling layers).\n",
        "\n",
        "For classification, you may use fc layer for the last layer right before prediction, as seen in VGG11 (in assignment 1.1). However, this last fc layer for classification may not be appropriate for solving segmentation problem, as they collapse spatial information. In order to preserve such info during process, you may exploit convolutional layer for the last part; this idean can be seen in papers like [1].\n",
        "\n",
        "\n",
        "[[1] Long et al, Fully Convolutional Networks for Semantic Segmentation, CVPR 2015](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)"
      ],
      "metadata": {
        "id": "6Sc2_SIRxUKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "m5V6rLrBxWJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below implements customed-VGG11 model composed of backbone and appropraite modules. Please fill in  2 **TO DO** and check the following answers with **calc_answer** functions below.\n",
        "\n",
        "\n",
        "- **TO DO (1)** : You should build a layer for the semantic segmentation. (Hint: Take a look at the **forward** method)\n",
        "\n",
        "- **TO DO (2)** : You should reshape & copy the parameter of **fc_out** layer of model for classification into defining layer (in Todo 1).\n",
        "\n",
        "- **Hint** : You may use the functions below to fill in Todo's:    \n",
        "(1) torch.reshape    \n",
        "(2) torch.nn.Conv2d    \n",
        "(3) torch.nn.Parameter"
      ],
      "metadata": {
        "id": "8uagODLcxX8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class VGG11BackBone(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(VGG11BackBone, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        #Convolution Feature Extraction Part\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 3, padding = 1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size = 3, padding = 1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size = 3, padding = 1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(256)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\n",
        "        self.bn3_2 = nn.BatchNorm2d(256)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size = 3, padding = 1)\n",
        "        self.bn4_1 = nn.BatchNorm2d(512)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size = 3, padding = 1)\n",
        "        self.bn4_2 = nn.BatchNorm2d(512)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size = 3, padding = 1)\n",
        "        self.bn5_1 = nn.BatchNorm2d(512)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size = 3, padding = 1)\n",
        "        self.bn5_2 = nn.BatchNorm2d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.bn3_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3_2(x)\n",
        "        x = self.bn3_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.conv4_1(x)\n",
        "        x = self.bn4_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv4_2(x)\n",
        "        x = self.bn4_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        x = self.conv5_1(x)\n",
        "        x = self.bn5_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv5_2(x)\n",
        "        x = self.bn5_2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "q_pZ8455xSoU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG11Classification(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes = 7):\n",
        "\n",
        "        super(VGG11Classification, self).__init__()\n",
        "\n",
        "        self.backbone = VGG11BackBone()\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc_out = nn.Linear(512, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.backbone(x)\n",
        "        x = self.pool5(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "1mFQO1GIzArl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG11Segmentation(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes = 7):\n",
        "\n",
        "        super(VGG11Segmentation, self).__init__()\n",
        "\n",
        "        self.backbone = VGG11BackBone()\n",
        "\n",
        "        '''==========================================================='''\n",
        "        '''======================== TO DO (1) ========================'''\n",
        "        #build a layer for the semantic segmentation.\n",
        "        with torch.no_grad():\n",
        "\n",
        "            self.conv_out = nn.Conv2d(512, num_classes, kernel_size = 1, padding = 0, stride = 1)\n",
        "\n",
        "        '''==========================================================='''\n",
        "        '''======================== TO DO (1) ========================'''\n",
        "\n",
        "        print(torch.nn.Parameter(self.conv_out.weight).size())\n",
        "\n",
        "        self.upsample = torch.nn.Upsample(scale_factor = 16, mode = 'bilinear', align_corners = False)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.backbone(x)\n",
        "        x = self.conv_out(x)\n",
        "        x = self.upsample(x)\n",
        "\n",
        "        assert x.shape == (1,7,224,224)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def copy_last_layer(self, fc_out):\n",
        "\n",
        "        \"\"\"\n",
        "        Copy last pre-trained fully-connected layer of classification model\n",
        "        into self.conv_out layer of segmentation model in appropriate shape\n",
        "\n",
        "        Keyword arguments:\n",
        "        fc_out: the fc layer of classification model (with shape of (7, 512))\n",
        "        \"\"\"\n",
        "\n",
        "        '''==========================================================='''\n",
        "        '''======================== TO DO (2) ========================'''\n",
        "\n",
        "        #You should reshape & copy the parameter of **fc_out** layer of model for classification into defining layer\n",
        "\n",
        "        reshaped_fc_out = fc_out.weight.detach()\n",
        "        reshaped_fc_out = torch.reshape(reshaped_fc_out, (7, 512, 1, 1))\n",
        "        self.conv_out.weight = torch.nn.Parameter(reshaped_fc_out)\n",
        "\n",
        "        '''==========================================================='''\n",
        "        '''======================== TO DO (2) ========================'''\n",
        "\n",
        "        assert self.conv_out.weight[0][0] == fc_out.weight[0][0]\n",
        "\n",
        "        return"
      ],
      "metadata": {
        "id": "KcUhLWlMzhtn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "\n",
        "test_input = torch.randn((1,3,224,224))\n",
        "\n",
        "modelC = VGG11Classification()\n",
        "out = modelC(test_input)\n",
        "print(out.shape)\n",
        "\n",
        "modelS = VGG11Segmentation()\n",
        "out = modelS(test_input)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p80WRFU3Dmv",
        "outputId": "b2f011c0-551b-4a36-bf54-066e571f6d71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 7])\n",
            "torch.Size([7, 512, 1, 1])\n",
            "torch.Size([1, 7, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w5FkGxbX3jfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader"
      ],
      "metadata": {
        "id": "bmtgwoRM3mcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataloader is slightly modified from assignment1.1, since we may not use train/valid data, but only few images for inference on segmentation problem."
      ],
      "metadata": {
        "id": "J2SgGJ-73oHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "PArpbJae3mn-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_root, input_size = 224, transform = None):\n",
        "\n",
        "        super(MaskDataset, self).__init__()\n",
        "\n",
        "        self.img_list = glob(os.path.join(data_root, '*.jpg'))\n",
        "        self.len = len(self.img_list)\n",
        "        self.input_size = input_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img_path = self.img_list[index]\n",
        "\n",
        "        #image loading\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = img/255.\n",
        "\n",
        "        if self.transform:\n",
        "\n",
        "            img = self.transform(img)\n",
        "\n",
        "        #ground truth\n",
        "        label = self._get_class_idx_from_img_name(img_path)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return self.len\n",
        "\n",
        "    def _get_class_idx_from_img_name(self, img_path):\n",
        "\n",
        "        img_name = os.path.basename(img_path)\n",
        "\n",
        "        if 'normal' in img_name:\n",
        "\n",
        "            return 0\n",
        "\n",
        "        elif 'mask1' in img_name:\n",
        "\n",
        "            return 1\n",
        "\n",
        "        elif 'mask2' in img_name:\n",
        "\n",
        "            return 2\n",
        "\n",
        "        elif 'mask3' in img_name:\n",
        "\n",
        "            return 3\n",
        "\n",
        "        elif 'mask4' in img_name:\n",
        "\n",
        "            return 4\n",
        "\n",
        "        elif 'mask5' in img_name:\n",
        "\n",
        "            return 5\n",
        "\n",
        "        elif 'incorrect_mask' in img_name:\n",
        "\n",
        "            return 6\n",
        "\n",
        "        else:\n",
        "\n",
        "            raise ValueError(\"%s is not a valid filename. Please change the name of %s.\" % (img_name, img_path))"
      ],
      "metadata": {
        "id": "QjQeaB655Q5D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight Reshaping"
      ],
      "metadata": {
        "id": "-shNGRmU6Z5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading model"
      ],
      "metadata": {
        "id": "8Gns3d_K6b2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## model loading\n",
        "model_root = './model.pth'\n",
        "\n",
        "modelC = VGG11Classification()\n",
        "modelC.load_state_dict(torch.load(model_root, map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL2p54YF6XbB",
        "outputId": "cd0adcae-0ea6-4a07-ce69-89c168473179"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy weight to reshape"
      ],
      "metadata": {
        "id": "Nfm2qqJR60xr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we copy the last layer of pretrained model for classification task into new model for segmentation task using 1x1 fully-convolutional layer. In order to fit into the new model, the weight should be reshaped."
      ],
      "metadata": {
        "id": "AP51QTKw62S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## copy weight\n",
        "modelS = VGG11Segmentation()\n",
        "modelS.backbone = modelC.backbone\n",
        "\n",
        "w_fc = modelC.fc_out\n",
        "modelS.copy_last_layer(w_fc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFta7eHU6jn9",
        "outputId": "822ec5b7-f281-4bbd-f061-b466d932c851"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 512, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "POMAvXwK7EH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may test on your segmentation model with prepared data with below cells.\n",
        "\n",
        "The below figure is an example result. You may check that the model is focusing on the part around the mask in the image, so can extract mask segmentation."
      ],
      "metadata": {
        "id": "CYLGkkoO7Fvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image loading\n",
        "data_root = './data'\n",
        "\n",
        "input_size = 224\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
        "                         std = [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "test_dataset = MaskDataset(data_root, input_size = input_size, transform = transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size = batch_size, pin_memory = True, shuffle = True)"
      ],
      "metadata": {
        "id": "0ts3PvB67AkO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "\n",
        "#test on segmentation\n",
        "modelS.cuda().float()\n",
        "modelS.eval()\n",
        "\n",
        "for iter, (img, label) in enumerate(test_loader):\n",
        "\n",
        "    img = img.float().cuda()\n",
        "\n",
        "    #inference for semantic segmentation\n",
        "    res = modelS(img)[0]\n",
        "\n",
        "    heat = res[label[0]]\n",
        "    resH = heat.cpu().detach().numpy()\n",
        "    heatR, heatC = np.where(resH > np.percentile(resH, 95))\n",
        "\n",
        "    seg = torch.argmax(res, dim = 0)\n",
        "    seg = seg.cpu().detach().numpy()\n",
        "    [segR,segC] = np.where(seg == np.int(label[0].cpu()))\n",
        "\n",
        "    resS = np.zeros((224, 224))\n",
        "\n",
        "    for i,r in enumerate(heatR):\n",
        "\n",
        "        c = heatC[i]\n",
        "\n",
        "        if (r in segR) and (c in segC):\n",
        "\n",
        "            resS[r,c] = 1\n",
        "\n",
        "    want_to_check_heat_map_result = False\n",
        "\n",
        "    #plot segmentation result\n",
        "    matplotlib.pyplot.imshow(img[0].cpu().permute(1, 2, 0))\n",
        "    if want_to_check_heat_map_result:\n",
        "\n",
        "        matplotlib.pyplot.imshow(resH,cmap='jet',alpha = 0.3)\n",
        "\n",
        "    matplotlib.pyplot.imshow(resS,alpha = 0.4)\n",
        "    matplotlib.pyplot.show()"
      ],
      "metadata": {
        "id": "76uATE_E7tzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xVt3rs9s7zdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Disccusion**\n",
        "\n",
        "You may also check heatmap result with **want_to_check_heat_map_result** flag. This might be helpful to notice why model is showing such results."
      ],
      "metadata": {
        "id": "dJ2iACFV9OW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "\n",
        "#test on segmentation\n",
        "modelS.cuda().float()\n",
        "modelS.eval()\n",
        "\n",
        "for iter, (img, label) in enumerate(test_loader):\n",
        "\n",
        "    img = img.float().cuda()\n",
        "\n",
        "    #inference for semantic segmentation\n",
        "    res = modelS(img)[0]\n",
        "\n",
        "    heat = res[label[0]]\n",
        "    resH = heat.cpu().detach().numpy()\n",
        "    heatR, heatC = np.where(resH > np.percentile(resH, 95))\n",
        "\n",
        "    seg = torch.argmax(res, dim = 0)\n",
        "    seg = seg.cpu().detach().numpy()\n",
        "    [segR,segC] = np.where(seg == np.int(label[0].cpu()))\n",
        "\n",
        "    resS = np.zeros((224, 224))\n",
        "\n",
        "    for i,r in enumerate(heatR):\n",
        "\n",
        "        c = heatC[i]\n",
        "\n",
        "        if (r in segR) and (c in segC):\n",
        "\n",
        "            resS[r,c] = 1\n",
        "\n",
        "    want_to_check_heat_map_result = True\n",
        "\n",
        "    #plot segmentation result\n",
        "    matplotlib.pyplot.imshow(img[0].cpu().permute(1, 2, 0))\n",
        "    if want_to_check_heat_map_result:\n",
        "\n",
        "        matplotlib.pyplot.imshow(resH,cmap='jet',alpha = 0.3)\n",
        "\n",
        "    matplotlib.pyplot.imshow(resS,alpha = 0.4)\n",
        "    matplotlib.pyplot.show()"
      ],
      "metadata": {
        "id": "UOr4p7E99OlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7RyLFYZA9THk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answers"
      ],
      "metadata": {
        "id": "EHsNJNal9cg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cells below implements simple function that compute the answer for the problem you will be submit on edwith. With proper code filled, you will get an integer answer."
      ],
      "metadata": {
        "id": "Y-7FGLa09eAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_answer_2_1(model):\n",
        "  \"\"\"\n",
        "  Compute the size of conv_out layer in modified model for solving semantic segmentation task\n",
        "  \"\"\"\n",
        "  answer  = 0\n",
        "\n",
        "  size = model.conv_out.weight.size()\n",
        "  for s in size:\n",
        "    answer += s\n",
        "\n",
        "  return answer\n",
        "\n",
        "\n",
        "print(f\"The answer for problem (1) is {calc_answer_2_1(modelS)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAlGfhkX9cq-",
        "outputId": "9b891ef5-f34a-4048-cf4f-c42456c5923c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The answer for problem (1) is 521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_answer_2_2(model, dataloader):\n",
        "  \"\"\"\n",
        "  Compute the overall sum of data in row of segmentation result, from input image data with label of 6\n",
        "  \"\"\"\n",
        "  answer = 0\n",
        "\n",
        "  for iter, (img, label) in enumerate(test_loader):\n",
        "    if label == 6:\n",
        "      img = img.float().cuda()\n",
        "      res = modelS(img)[0]\n",
        "\n",
        "      heat = res[label[0]]\n",
        "      resH = heat.cpu().detach().numpy()\n",
        "      heatR, heatC = np.where(resH > np.percentile(resH, 95))\n",
        "\n",
        "      seg = torch.argmax(res, dim=0)\n",
        "      seg = seg.cpu().detach().numpy()\n",
        "      [segR, segC] = np.where(seg == np.int(label[0].cpu()))\n",
        "\n",
        "      resS = np.zeros((224,224))\n",
        "      for i, r in enumerate(heatR):\n",
        "        c = heatC[i]\n",
        "        if (r in segR) and (c in segC):\n",
        "          answer += r\n",
        "\n",
        "  return answer\n",
        "\n",
        "print(f\"The answer for problem (2) is {calc_answer_2_2(modelS, test_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgZHUBLf9f-o",
        "outputId": "b057aea3-b693-4811-daee-0eeb90491cbb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-94e2f4e74dbb>:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  [segR, segC] = np.where(seg == np.int(label[0].cpu()))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The answer for problem (2) is 320239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4zBsar7t9iM1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}