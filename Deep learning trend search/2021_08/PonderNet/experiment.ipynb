{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DgVKWlJnz3i"
      },
      "source": [
        "## reference\n",
        "\n",
        "https://github.com/labmlai/annotated_deep_learning_paper_implementations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALxyHuBYnyJb"
      },
      "source": [
        "## load library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHLrcjX877JD",
        "outputId": "169e9ff8-b9ec-4fb8-da82-9c5642973492"
      },
      "source": [
        "!pip install labml"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting labml\n",
            "  Downloading labml-0.4.132-py3-none-any.whl (121 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▊                             | 10 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 121 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from labml) (3.13)\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 25.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from labml) (1.19.5)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython->labml) (3.7.4.3)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython, labml\n",
            "Successfully installed gitdb-4.0.7 gitpython-3.1.18 labml-0.4.132 smmap-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdRkHRks7-tS",
        "outputId": "1846f93e-25b9-4e49-fa9a-3be30a26b419"
      },
      "source": [
        "!pip install labml_helpers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting labml_helpers\n",
            "  Downloading labml_helpers-0.4.81-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from labml_helpers) (1.9.0+cu102)\n",
            "Requirement already satisfied: labml>=0.4.129 in /usr/local/lib/python3.7/dist-packages (from labml_helpers) (0.4.132)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from labml>=0.4.129->labml_helpers) (3.13)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from labml>=0.4.129->labml_helpers) (3.1.18)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from labml>=0.4.129->labml_helpers) (1.19.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->labml>=0.4.129->labml_helpers) (4.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython->labml>=0.4.129->labml_helpers) (3.7.4.3)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->labml>=0.4.129->labml_helpers) (4.0.0)\n",
            "Installing collected packages: labml-helpers\n",
            "Successfully installed labml-helpers-0.4.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqd7Pl6T8BR2",
        "outputId": "384c2977-9a29-47b9-a4bf-4a2d78659a01"
      },
      "source": [
        "!pip install labml_nn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting labml_nn\n",
            "  Downloading labml_nn-0.4.109-py3-none-any.whl (274 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 274 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from labml_nn) (1.19.5)\n",
            "Requirement already satisfied: labml>=0.4.129 in /usr/local/lib/python3.7/dist-packages (from labml_nn) (0.4.132)\n",
            "Collecting einops\n",
            "  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: labml-helpers>=0.4.81 in /usr/local/lib/python3.7/dist-packages (from labml_nn) (0.4.81)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from labml_nn) (1.9.0+cu102)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from labml>=0.4.129->labml_nn) (3.13)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from labml>=0.4.129->labml_nn) (3.1.18)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython->labml>=0.4.129->labml_nn) (3.7.4.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->labml>=0.4.129->labml_nn) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->labml>=0.4.129->labml_nn) (4.0.0)\n",
            "Installing collected packages: einops, labml-nn\n",
            "Successfully installed einops-0.3.0 labml-nn-0.4.109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYri_tkjHtdV"
      },
      "source": [
        "from typing import Any,Tuple\n",
        "\n",
        "from abc import ABC\n",
        "\n",
        "import dataclasses\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "\n",
        "from labml import tracker, experiment\n",
        "from labml_helpers.train_valid import SimpleTrainValidConfigs, BatchIndex\n",
        "from labml_nn.adaptive_computation.ponder_net import ParityPonderGRU, ReconstructionLoss, RegularizationLoss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4NjHYgOnwEq"
      },
      "source": [
        "## prepare metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B120GMA4IGjN"
      },
      "source": [
        "@dataclasses.dataclass\n",
        "class AccuracyState:\n",
        "    samples: int = 0\n",
        "    correct: int = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.samples = 0\n",
        "        self.correct = 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoHA7KgQIdu8"
      },
      "source": [
        "class StateModule:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # def __call__(self):\n",
        "    #     raise NotImplementedError\n",
        "\n",
        "    def create_state(self) -> any:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def set_state(self, data: any):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def on_epoch_start(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        raise NotImplementedError"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS_QNfd8IiKv"
      },
      "source": [
        "class Metric(StateModule, ABC):\n",
        "    def track(self):\n",
        "        pass"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6HjO1vBIWVY"
      },
      "source": [
        "class Accuracy(Metric):\n",
        "    data: AccuracyState\n",
        "\n",
        "    def __init__(self, ignore_index: int = -1):\n",
        "        super().__init__()\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def __call__(self, output: torch.Tensor, target: torch.Tensor):\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target = target.view(-1)\n",
        "        pred = output.argmax(dim=-1)\n",
        "        mask = target == self.ignore_index\n",
        "        pred.masked_fill_(mask, self.ignore_index)\n",
        "        n_masked = mask.sum().item()\n",
        "        self.data.correct += pred.eq(target).sum().item() - n_masked\n",
        "        self.data.samples += len(target) - n_masked\n",
        "\n",
        "    def create_state(self):\n",
        "        return AccuracyState()\n",
        "\n",
        "    def set_state(self, data: any):\n",
        "        self.data = data\n",
        "\n",
        "    def on_epoch_start(self):\n",
        "        self.data.reset()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.track()\n",
        "\n",
        "    def track(self):\n",
        "        if self.data.samples == 0:\n",
        "            return\n",
        "        tracker.add(\"accuracy.\", self.data.correct / self.data.samples)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oAbURlAIC_1"
      },
      "source": [
        "class AccuracyDirect(Accuracy):\n",
        "    data: AccuracyState\n",
        "\n",
        "    def __call__(self, output: torch.Tensor, target: torch.Tensor):\n",
        "        output = output.view(-1)\n",
        "        target = target.view(-1)\n",
        "        self.data.correct += output.eq(target).sum().item()\n",
        "        self.data.samples += len(target)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaaRBtf6Hhmh"
      },
      "source": [
        "##parity task dataset\n",
        "\n",
        "**parity\n",
        "\n",
        "The input vectors had 64 elements, of which a random number from 1 to 64 were randomly set\n",
        "to 1 or −1 and the rest were set to 0. The corresponding target was 1 if there was an odd number\n",
        "of ones and 0 if there was an even number of ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJIDGkjkHnfV"
      },
      "source": [
        "class ParityDataset(Dataset):\n",
        "    \"\"\"\n",
        "    ### Parity dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_samples: int, n_elems: int = 64):\n",
        "        \"\"\"\n",
        "        * `n_samples` is the number of samples\n",
        "        * `n_elems` is the number of elements in the input vector\n",
        "        \"\"\"\n",
        "        self.n_samples = n_samples\n",
        "        self.n_elems = n_elems\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Size of the dataset\n",
        "        \"\"\"\n",
        "        return self.n_samples\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Generate a sample\n",
        "        \"\"\"\n",
        "\n",
        "        # Empty vector\n",
        "        x = torch.zeros((self.n_elems,))\n",
        "        # Number of non-zero elements - a random number between $1$ and total number of elements\n",
        "        n_non_zero = torch.randint(1, self.n_elems + 1, (1,)).item()\n",
        "        # Fill non-zero elements with $1$'s and $-1$'s\n",
        "        x[:n_non_zero] = torch.randint(0, 2, (n_non_zero,)) * 2 - 1\n",
        "        # Randomly permute the elements\n",
        "        x = x[torch.randperm(self.n_elems)]\n",
        "\n",
        "        # The parity\n",
        "        y = (x == 1.).sum() % 2\n",
        "\n",
        "        #\n",
        "        return x, y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWDASHfF8k3u"
      },
      "source": [
        "## define configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2ZYKZIh8jbl"
      },
      "source": [
        "class Configs(SimpleTrainValidConfigs):\n",
        "    \"\"\"\n",
        "    Configurations with a\n",
        "     [simple training loop](https://docs.labml.ai/api/helpers.html#labml_helpers.train_valid.SimpleTrainValidConfigs)\n",
        "    \"\"\"\n",
        "\n",
        "    # Number of epochs\n",
        "    epochs: int = 5\n",
        "    # Number of batches per epoch\n",
        "    n_batches: int = 500\n",
        "    # Batch size\n",
        "    batch_size: int = 128\n",
        "\n",
        "    # Model\n",
        "    model: ParityPonderGRU\n",
        "\n",
        "    # $L_{Rec}$\n",
        "    loss_rec: ReconstructionLoss\n",
        "    # $L_{Reg}$\n",
        "    loss_reg: RegularizationLoss\n",
        "\n",
        "    # The number of elements in the input vector.\n",
        "    # *We keep it low for demonstration; otherwise, training takes a lot of time.\n",
        "    # Although the parity task seems simple, figuring out the pattern by looking at samples\n",
        "    # is quite hard.*\n",
        "    n_elems: int = 8\n",
        "    # Number of units in the hidden layer (state)\n",
        "    n_hidden: int = 64\n",
        "    # Maximum number of steps $N$\n",
        "    max_steps: int = 20\n",
        "\n",
        "    # $\\lambda_p$ for the geometric distribution $p_G(\\lambda_p)$\n",
        "    lambda_p: float = 0.2\n",
        "    # Regularization loss $L_{Reg}$ coefficient $\\beta$\n",
        "    beta: float = 0.01\n",
        "\n",
        "    # Gradient clipping by norm\n",
        "    grad_norm_clip: float = 1.0\n",
        "\n",
        "    # Training and validation loaders\n",
        "    train_loader: DataLoader\n",
        "    valid_loader: DataLoader\n",
        "\n",
        "    # Accuracy calculator\n",
        "    accuracy = AccuracyDirect()\n",
        "\n",
        "    def init(self):\n",
        "        # Print indicators to screen\n",
        "        tracker.set_scalar('loss.*', True)\n",
        "        tracker.set_scalar('loss_reg.*', True)\n",
        "        tracker.set_scalar('accuracy.*', True)\n",
        "        tracker.set_scalar('steps.*', True)\n",
        "\n",
        "        # We need to set the metrics to calculate them for the epoch for training and validation\n",
        "        self.state_modules = [self.accuracy]\n",
        "\n",
        "        # Initialize the model\n",
        "        self.model = ParityPonderGRU(self.n_elems, self.n_hidden, self.max_steps).to(self.device)\n",
        "        # $L_{Rec}$\n",
        "        self.loss_rec = ReconstructionLoss(nn.BCEWithLogitsLoss(reduction='none')).to(self.device)\n",
        "        # $L_{Reg}$\n",
        "        self.loss_reg = RegularizationLoss(self.lambda_p, self.max_steps).to(self.device)\n",
        "\n",
        "        # Training and validation loaders\n",
        "        self.train_loader = DataLoader(ParityDataset(self.batch_size * self.n_batches, self.n_elems),\n",
        "                                       batch_size=self.batch_size)\n",
        "        self.valid_loader = DataLoader(ParityDataset(self.batch_size * 32, self.n_elems),\n",
        "                                       batch_size=self.batch_size)\n",
        "\n",
        "    def step(self, batch: Any, batch_idx: BatchIndex):\n",
        "        \"\"\"\n",
        "        This method gets called by the trainer for each batch\n",
        "        \"\"\"\n",
        "        # Set the model mode\n",
        "        self.model.train(self.mode.is_train)\n",
        "\n",
        "        # Get the input and labels and move them to the model's device\n",
        "        data, target = batch[0].to(self.device), batch[1].to(self.device)\n",
        "\n",
        "        # Increment step in training mode\n",
        "        if self.mode.is_train:\n",
        "            tracker.add_global_step(len(data))\n",
        "\n",
        "        # Run the model\n",
        "        p, y_hat, p_sampled, y_hat_sampled = self.model(data)\n",
        "\n",
        "        # Calculate the reconstruction loss\n",
        "        loss_rec = self.loss_rec(p, y_hat, target.to(torch.float))\n",
        "        tracker.add(\"loss.\", loss_rec)\n",
        "\n",
        "        # Calculate the regularization loss\n",
        "        loss_reg = self.loss_reg(p)\n",
        "        tracker.add(\"loss_reg.\", loss_reg)\n",
        "\n",
        "        # $L = L_{Rec} + \\beta L_{Reg}$\n",
        "        loss = loss_rec + self.beta * loss_reg\n",
        "\n",
        "        # Calculate the expected number of steps taken\n",
        "        steps = torch.arange(1, p.shape[0] + 1, device=p.device)\n",
        "        expected_steps = (p * steps[:, None]).sum(dim=0)\n",
        "        tracker.add(\"steps.\", expected_steps)\n",
        "\n",
        "        # Call accuracy metric\n",
        "        self.accuracy(y_hat_sampled > 0, target)\n",
        "\n",
        "        if self.mode.is_train:\n",
        "            # Compute gradients\n",
        "            loss.backward()\n",
        "            # Clip gradients\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=self.grad_norm_clip)\n",
        "            # Optimizer\n",
        "            self.optimizer.step()\n",
        "            # Clear gradients\n",
        "            self.optimizer.zero_grad()\n",
        "            #\n",
        "            tracker.save()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "XUqL6Kpq8ovz",
        "outputId": "d291445e-b89d-486f-e004-25f94fd24af1"
      },
      "source": [
        "experiment.create(name='ponder_net')\n",
        "\n",
        "conf = Configs()\n",
        "experiment.configs(conf, {\n",
        "    'optimizer.optimizer': 'Adam',\n",
        "    'optimizer.learning_rate': 0.0003,\n",
        "})\n",
        "\n",
        "with experiment.start():\n",
        "    conf.run()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"overflow-x: scroll;\">\n",
              "\n",
              "<strong><span style=\"text-decoration: underline\">ponder_net</span></strong>: <span style=\"color: #208FFB\">6a0920bc074711ecbb660242ac1c0002</span>\n",
              "\t[dirty]: <strong><span style=\"color: #DDB62B\">\"\"</span></strong>\n",
              "<strong>~/labml/configs.yaml</strong> does not exist. Creating <span style=\"color: #208FFB\">/root/.labml/configs.yaml</span>\n",
              "Initialize...\n",
              "  Prepare device...\n",
              "    Prepare device_info<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t22.37ms</span>\n",
              "  Prepare device<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t36.04ms</span>\n",
              "<span style=\"color: #C5C1B4\"></span>\n",
              "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
              "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
              "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>Failed to send to https://api.labml.ai/api/v1/track?run_uuid=6a0920bc074711ecbb660242ac1c0002&labml_version=0.4.132: <strong>500</strong>\n",
              "Internal Server Error<span style=\"color: #C5C1B4\"></span>\n",
              "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
              "<strong><span style=\"color: #DDB62B\">Retrying again in 10 seconds (0)...</span></strong>\n",
              "Initialize<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t297.29ms</span>\n",
              "Prepare validator...\n",
              "  Prepare mode<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t4.22ms</span>\n",
              "Prepare validator<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t148.69ms</span>\n",
              "Prepare trainer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t38.84ms</span>\n",
              "Prepare training_loop...\n",
              "  Prepare loop_count<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t40.63ms</span>\n",
              "Prepare training_loop<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t258.14ms</span>\n",
              "<span style=\"color: #C5C1B4\"></span>\n",
              "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
              "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
              "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>Failed to send to https://api.labml.ai/api/v1/track?run_uuid=6a0920bc074711ecbb660242ac1c0002&labml_version=0.4.132: <strong>500</strong>\n",
              "Internal Server Error<span style=\"color: #C5C1B4\"></span>\n",
              "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
              "<strong><span style=\"color: #DDB62B\">Retrying again in 10 seconds (1)...</span></strong>\n",
              "<span style=\"color: #C5C1B4\"></span>\n",
              "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
              "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
              "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>LabML App Warning: <span style=\"color: #60C6C8\">empty_token: </span><strong>Please create a valid token at https://app.labml.ai.</strong>\n",
              "<strong>Click on the experiment link to monitor the experiment and add it to your experiments list.</strong><span style=\"color: #C5C1B4\"></span>\n",
              "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
              "<span style=\"color: #208FFB\">Monitor experiment at </span><a href='https://app.labml.ai/run/6a0920bc074711ecbb660242ac1c0002' target='blank'>https://app.labml.ai/run/6a0920bc074711ecbb660242ac1c0002</a>\n",
              "<strong><span style=\"color: #DDB62B\">  64,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  28,851ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 543ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.684885</span> loss_reg.train: <span style=\"color: #C5C1B4\">0.058064</span> steps.train: <span style=\"color: #C5C1B4\"> 3.90297</span> accuracy.train: <span style=\"color: #C5C1B4\">0.544078</span> loss.valid: <span style=\"color: #C5C1B4\">0.690325</span> loss_reg.valid: <span style=\"color: #C5C1B4\">0.056929</span> steps.valid: <span style=\"color: #C5C1B4\"> 3.91486</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.536865</span>  <span style=\"color: #208FFB\">30,591ms</span><span style=\"color: #D160C4\">  0:00m/  0:02m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 128,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  28,851ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 543ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.684818</span> loss_reg.train: <span style=\"color: #C5C1B4\">0.015314</span> steps.train: <span style=\"color: #C5C1B4\"> 4.36373</span> accuracy.train: <span style=\"color: #C5C1B4\">0.529891</span> loss.valid: <span style=\"color: #C5C1B4\">0.693677</span> loss_reg.valid: <span style=\"color: #C5C1B4\">0.014397</span> steps.valid: <span style=\"color: #C5C1B4\"> 4.38069</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.498535</span>  <span style=\"color: #208FFB\">32,016ms</span><span style=\"color: #D160C4\">  0:01m/  0:01m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 192,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  28,851ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 543ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.682191</span> loss_reg.train: <span style=\"color: #C5C1B4\">0.001785</span> steps.train: <span style=\"color: #C5C1B4\"> 4.56814</span> accuracy.train: <span style=\"color: #C5C1B4\">0.535922</span> loss.valid: <span style=\"color: #C5C1B4\">0.691005</span> loss_reg.valid: <span style=\"color: #C5C1B4\">0.001765</span> steps.valid: <span style=\"color: #C5C1B4\"> 4.56606</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.531738</span>  <span style=\"color: #208FFB\">32,403ms</span><span style=\"color: #D160C4\">  0:01m/  0:01m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 256,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  28,851ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 543ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.688412</span> loss_reg.train: <span style=\"color: #C5C1B4\">-0.003715</span> steps.train: <span style=\"color: #C5C1B4\"> 4.71813</span> accuracy.train: <span style=\"color: #C5C1B4\">0.540672</span> loss.valid: <span style=\"color: #C5C1B4\">0.692031</span> loss_reg.valid: <span style=\"color: #C5C1B4\">-0.003260</span> steps.valid: <span style=\"color: #C5C1B4\"> 4.71094</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.545654</span>  <span style=\"color: #208FFB\">32,556ms</span><span style=\"color: #D160C4\">  0:02m/  0:00m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 320,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.684738</span> loss_reg.train: <span style=\"color: #C5C1B4\">0.007276</span> steps.train: <span style=\"color: #C5C1B4\"> 5.30061</span> accuracy.train: <span style=\"color: #C5C1B4\">0.546500</span> loss.valid: <span style=\"color: #C5C1B4\">0.689956</span> loss_reg.valid: <span style=\"color: #C5C1B4\">0.007682</span> steps.valid: <span style=\"color: #C5C1B4\"> 5.32456</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.546143</span>\n",
              "<strong><span style=\"color: #DDB62B\">Still updating app.labml.ai, please wait for it to complete...</span></strong></pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A1E_fXetZZe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}