{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2cf8d18de154431ae8da776d4637554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_109f6b622c564e3593905191348d5f6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9fbe9c0f8a0c459fbafe9a7d0bc9147c",
              "IPY_MODEL_a7390b2f0b3d4ca1a3d5c51d3bb72187",
              "IPY_MODEL_eb9467e0104045bba03d263008d46d47"
            ]
          }
        },
        "109f6b622c564e3593905191348d5f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fbe9c0f8a0c459fbafe9a7d0bc9147c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_156488a2b4d044d7a23fec084290908f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bc018f8f5914a26a47a3fa10b956970"
          }
        },
        "a7390b2f0b3d4ca1a3d5c51d3bb72187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c87ccf04d4c6449bbbc02dc4798ad912",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b114021222b743e4897e886a7c49c43f"
          }
        },
        "eb9467e0104045bba03d263008d46d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b7b411eb7324558a0d2666e6bef71ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00, 28.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_497e8d4c5284495e989e7e6ac5a17637"
          }
        },
        "156488a2b4d044d7a23fec084290908f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bc018f8f5914a26a47a3fa10b956970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c87ccf04d4c6449bbbc02dc4798ad912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b114021222b743e4897e886a7c49c43f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b7b411eb7324558a0d2666e6bef71ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "497e8d4c5284495e989e7e6ac5a17637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88mMrhxAuXwY"
      },
      "source": [
        "## reference : https://github.com/wuch15/Fastformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTGiF1j-ufQM"
      },
      "source": [
        "## load library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP_r1B6OuZdv"
      },
      "source": [
        "from datasets import load_dataset\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import logging\n",
        "\n",
        "from transformers import BertConfig\n",
        "from transformers.models.bert.modeling_bert import BertSelfOutput, BertIntermediate, BertOutput\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import *"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crIFvdUyz_eO"
      },
      "source": [
        "## hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPXqmfG-vKKR"
      },
      "source": [
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "config = BertConfig.from_json_file('fastformer.json')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVPBBB9Ws2eu"
      },
      "source": [
        "## metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cuc-xKNLs4JQ"
      },
      "source": [
        "def acc(y_true, y_hat):\n",
        "    y_hat = torch.argmax(y_hat, dim=-1)\n",
        "    tot = y_true.shape[0]\n",
        "    hit = torch.sum(y_true == y_hat)\n",
        "    return hit.data.float() * 1.0 / tot"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhgrqEv_vKfn"
      },
      "source": [
        "## create dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "f2cf8d18de154431ae8da776d4637554",
            "109f6b622c564e3593905191348d5f6d",
            "9fbe9c0f8a0c459fbafe9a7d0bc9147c",
            "a7390b2f0b3d4ca1a3d5c51d3bb72187",
            "eb9467e0104045bba03d263008d46d47",
            "156488a2b4d044d7a23fec084290908f",
            "8bc018f8f5914a26a47a3fa10b956970",
            "c87ccf04d4c6449bbbc02dc4798ad912",
            "b114021222b743e4897e886a7c49c43f",
            "3b7b411eb7324558a0d2666e6bef71ac",
            "497e8d4c5284495e989e7e6ac5a17637"
          ]
        },
        "id": "jANhm6tYuwZj",
        "outputId": "848d8d05-031d-4910-889f-134f67c6a50c"
      },
      "source": [
        "dataset = load_dataset('ag_news')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2cf8d18de154431ae8da776d4637554",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrwHItCkvQAP",
        "outputId": "9236558e-9f7b-4c83-fec0-febf271ee0ef"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 120000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 7600\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_0iRuXJvT-i"
      },
      "source": [
        "#split text & label\n",
        "\n",
        "text = []\n",
        "label = []\n",
        "\n",
        "for row in dataset['train']['text']+dataset['test']['text']: #train data(120000) + test data(7600)=127600\n",
        "    text.append(wordpunct_tokenize(row.lower()))\n",
        "\n",
        "for row in dataset['train']['label']+dataset['test']['label']:\n",
        "    label.append(row)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wyEHYF9vyvl",
        "outputId": "27f35dfe-eb0e-411b-9fb4-080d93bdddf6"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127600"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeBS58FazPrJ",
        "outputId": "82ab2391-d658-4f2b-c569-f119f13e6fff"
      },
      "source": [
        "text[1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['carlyle',\n",
              " 'looks',\n",
              " 'toward',\n",
              " 'commercial',\n",
              " 'aerospace',\n",
              " '(',\n",
              " 'reuters',\n",
              " ')',\n",
              " 'reuters',\n",
              " '-',\n",
              " 'private',\n",
              " 'investment',\n",
              " 'firm',\n",
              " 'carlyle',\n",
              " 'group',\n",
              " ',\\\\',\n",
              " 'which',\n",
              " 'has',\n",
              " 'a',\n",
              " 'reputation',\n",
              " 'for',\n",
              " 'making',\n",
              " 'well',\n",
              " '-',\n",
              " 'timed',\n",
              " 'and',\n",
              " 'occasionally',\n",
              " '\\\\',\n",
              " 'controversial',\n",
              " 'plays',\n",
              " 'in',\n",
              " 'the',\n",
              " 'defense',\n",
              " 'industry',\n",
              " ',',\n",
              " 'has',\n",
              " 'quietly',\n",
              " 'placed',\n",
              " '\\\\',\n",
              " 'its',\n",
              " 'bets',\n",
              " 'on',\n",
              " 'another',\n",
              " 'part',\n",
              " 'of',\n",
              " 'the',\n",
              " 'market',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKxwJZiuwtEA",
        "outputId": "23251101-3761-4397-c440-e5de1209beaf"
      },
      "source": [
        "len(label)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127600"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kmEXSqjzS61",
        "outputId": "add04fa1-5a79-4134-829a-26aa46261987"
      },
      "source": [
        "label[1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fbUBRNUwuR4"
      },
      "source": [
        "#create vocab\n",
        "\n",
        "word_dict = {'PADDING' : 0}\n",
        "\n",
        "for sent in text:\n",
        "    for token in sent:\n",
        "        if token not in word_dict:\n",
        "            word_dict[token]=len(word_dict)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-XjRaily10H",
        "outputId": "721dc536-5023-4636-ae93-4d185d4c178e"
      },
      "source": [
        "i = 0\n",
        "for word,value in word_dict.items():\n",
        "    print(word)\n",
        "    print(value)\n",
        "    i = i+1\n",
        "    if i == 5:\n",
        "        break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PADDING\n",
            "0\n",
            "wall\n",
            "1\n",
            "st\n",
            "2\n",
            ".\n",
            "3\n",
            "bears\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8wgeEk3xH3Y"
      },
      "source": [
        "#encoding text data using zero padding\n",
        "news_words = []\n",
        "\n",
        "for sent in text:\n",
        "    \n",
        "    sample = []\n",
        "\n",
        "    for token in sent:\n",
        "        sample.append(word_dict[token])\n",
        "    \n",
        "    sample = sample[:256]\n",
        "    news_words.append(sample+[0]*(256-len(sample)))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpH32d56x0Kb"
      },
      "source": [
        "#change list to array\n",
        "news_words = np.array(news_words,dtype='int32')\n",
        "label = np.array(label,dtype='int32')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjjWWMEXydJQ",
        "outputId": "e436b2b2-2abe-4a12-e0b5-4ce9ff69d0d8"
      },
      "source": [
        "news_words[1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30, 31, 32, 33, 34, 10, 11, 12, 11, 13, 35, 36, 37, 30, 38, 39, 40,\n",
              "       41, 42, 43, 44, 45, 46, 13, 47, 48, 49, 21, 50, 51, 52,  8, 53, 54,\n",
              "       16, 41, 55, 56, 21, 57, 58, 59, 60, 61, 23,  8, 62,  3,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUu8WZdgyvjo"
      },
      "source": [
        "#create data index\n",
        "\n",
        "index = np.arange(len(label))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E9tMI1Dza-0",
        "outputId": "29b418f7-df37-4d10-b2c6-a37ac751112a"
      },
      "source": [
        "index"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([     0,      1,      2, ..., 127597, 127598, 127599])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izoCiTHhzbjR"
      },
      "source": [
        "train_index = index[:120000]\n",
        "np.random.shuffle(train_index) #random shuffle"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YVBpwZmzqGx",
        "outputId": "698b5d85-0282-4929-97cf-80ba13154737"
      },
      "source": [
        "train_index"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([27397, 66817, 65375, ..., 48556, 50150, 87478])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG0-q9yCzrOY"
      },
      "source": [
        "test_index = index[120000:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La8CrtKbrc4y"
      },
      "source": [
        "## attention pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUykylyy0cCK"
      },
      "source": [
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        super(AttentionPooling, self).__init__()\n",
        "        self.att_fc1 = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.att_fc2 = nn.Linear(config.hidden_size, 1)\n",
        "        self.apply(self.init_weights)\n",
        "        \n",
        "    def init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "            \n",
        "                \n",
        "    def forward(self, x, attn_mask=None):\n",
        "        bz = x.shape[0]\n",
        "        e = self.att_fc1(x)\n",
        "        e = nn.Tanh()(e)\n",
        "        alpha = self.att_fc2(e)\n",
        "        alpha = torch.exp(alpha)\n",
        "        if attn_mask is not None:\n",
        "            alpha = alpha * attn_mask.unsqueeze(2)\n",
        "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
        "        x = torch.bmm(x.permute(0, 2, 1), alpha)\n",
        "        x = torch.reshape(x, (bz, -1))  \n",
        "        return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nMmG7KXsJGS"
      },
      "source": [
        "## additive attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWlF_RGdrvg6"
      },
      "source": [
        "class FastSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(FastSelfAttention, self).__init__()\n",
        "        self.config = config\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
        "                \"heads (%d)\" %\n",
        "                (config.hidden_size, config.num_attention_heads))\n",
        "        self.attention_head_size = int(config.hidden_size /config.num_attention_heads)\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "        self.input_dim= config.hidden_size\n",
        "        \n",
        "        self.query = nn.Linear(self.input_dim, self.all_head_size)\n",
        "        self.query_att = nn.Linear(self.all_head_size, self.num_attention_heads)\n",
        "        self.key = nn.Linear(self.input_dim, self.all_head_size)\n",
        "        self.key_att = nn.Linear(self.all_head_size, self.num_attention_heads)\n",
        "        self.transform = nn.Linear(self.all_head_size, self.all_head_size)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        \n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "                \n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads,\n",
        "                                       self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "    \n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        # batch_size, seq_len, num_head * head_dim, batch_size, seq_len\n",
        "        batch_size, seq_len, _ = hidden_states.shape\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        # batch_size, num_head, seq_len\n",
        "        query_for_score = self.query_att(mixed_query_layer).transpose(1, 2) / self.attention_head_size**0.5\n",
        "        # add attention mask\n",
        "        query_for_score += attention_mask\n",
        "\n",
        "        # batch_size, num_head, 1, seq_len\n",
        "        query_weight = self.softmax(query_for_score).unsqueeze(2)\n",
        "\n",
        "        # batch_size, num_head, seq_len, head_dim\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # batch_size, num_head, head_dim, 1\n",
        "        pooled_query = torch.matmul(query_weight, query_layer).transpose(1, 2).view(-1,1,self.num_attention_heads*self.attention_head_size)\n",
        "        pooled_query_repeat= pooled_query.repeat(1, seq_len,1)\n",
        "        # batch_size, num_head, seq_len, head_dim\n",
        "\n",
        "        # batch_size, num_head, seq_len\n",
        "        mixed_query_key_layer=mixed_key_layer* pooled_query_repeat\n",
        "        \n",
        "        query_key_score=(self.key_att(mixed_query_key_layer)/ self.attention_head_size**0.5).transpose(1, 2)\n",
        "        \n",
        "        # add attention mask\n",
        "        query_key_score +=attention_mask\n",
        "\n",
        "        # batch_size, num_head, 1, seq_len\n",
        "        query_key_weight = self.softmax(query_key_score).unsqueeze(2)\n",
        "\n",
        "        key_layer = self.transpose_for_scores(mixed_query_key_layer)\n",
        "        pooled_key = torch.matmul(query_key_weight, key_layer)\n",
        "\n",
        "        #query = value\n",
        "        weighted_value =(pooled_key * query_layer).transpose(1, 2)\n",
        "        weighted_value = weighted_value.reshape(\n",
        "            weighted_value.size()[:-2] + (self.num_attention_heads * self.attention_head_size,))\n",
        "        weighted_value = self.transform(weighted_value) + mixed_query_layer\n",
        "      \n",
        "        return weighted_value"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDvgrphAr-h1"
      },
      "source": [
        "class FastAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(FastAttention, self).__init__()\n",
        "        self.self = FastSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask):\n",
        "        self_output = self.self(input_tensor, attention_mask)\n",
        "        attention_output = self.output(self_output, input_tensor)\n",
        "        return attention_output"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZrwV5PosWCT"
      },
      "source": [
        "## fastformer encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMp6VqCgsH1X"
      },
      "source": [
        "class FastformerLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(FastformerLayer, self).__init__()\n",
        "        self.attention = FastAttention(config)\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        attention_output = self.attention(hidden_states, attention_mask)\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "        return layer_output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eITaMF4sX9-"
      },
      "source": [
        "class FastformerEncoder(nn.Module):\n",
        "    def __init__(self, config, pooler_count=1):\n",
        "        super(FastformerEncoder, self).__init__()\n",
        "        self.config = config\n",
        "        self.encoders = nn.ModuleList([FastformerLayer(config) for _ in range(config.num_hidden_layers)])\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # support multiple different poolers with shared bert encoder.\n",
        "        self.poolers = nn.ModuleList()\n",
        "        if config.pooler_type == 'weightpooler':\n",
        "            for _ in range(pooler_count):\n",
        "                self.poolers.append(AttentionPooling(config))\n",
        "        logging.info(f\"This model has {len(self.poolers)} poolers.\")\n",
        "\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if isinstance(module, (nn.Embedding)) and module.padding_idx is not None:\n",
        "                with torch.no_grad():\n",
        "                    module.weight[module.padding_idx].fill_(0)\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, \n",
        "                input_embs, \n",
        "                attention_mask, \n",
        "                pooler_index=0):\n",
        "        #input_embs: batch_size, seq_len, emb_dim\n",
        "        #attention_mask: batch_size, seq_len, emb_dim\n",
        "\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1)\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        batch_size, seq_length, emb_dim = input_embs.shape\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_embs.device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, -1)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "\n",
        "        embeddings = input_embs + position_embeddings\n",
        "        \n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        #print(embeddings.size())\n",
        "        all_hidden_states = [embeddings]\n",
        "\n",
        "        for i, layer_module in enumerate(self.encoders):\n",
        "            layer_outputs = layer_module(all_hidden_states[-1], extended_attention_mask)\n",
        "            all_hidden_states.append(layer_outputs)\n",
        "        assert len(self.poolers) > pooler_index\n",
        "        output = self.poolers[pooler_index](all_hidden_states[-1], attention_mask)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7SH9OGdsreS"
      },
      "source": [
        "## create fastformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEL3CcDNsjQL"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,config):\n",
        "        super(Model, self).__init__()\n",
        "        self.config = config\n",
        "        self.dense_linear = nn.Linear(config.hidden_size,4)\n",
        "        self.word_embedding = nn.Embedding(len(word_dict),256,padding_idx=0)\n",
        "        self.fastformer_model = FastformerEncoder(config)\n",
        "        self.criterion = nn.CrossEntropyLoss() \n",
        "        self.apply(self.init_weights)\n",
        "        \n",
        "    def init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if isinstance(module, (nn.Embedding)) and module.padding_idx is not None:\n",
        "                with torch.no_grad():\n",
        "                    module.weight[module.padding_idx].fill_(0)\n",
        "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "    \n",
        "    def forward(self,input_ids,targets):\n",
        "        mask=input_ids.bool().float()\n",
        "        embds=self.word_embedding(input_ids)\n",
        "        text_vec = self.fastformer_model(embds,mask)\n",
        "        score = self.dense_linear(text_vec)\n",
        "        loss = self.criterion(score, targets) \n",
        "        return loss, score"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShvgaMT5stmq"
      },
      "source": [
        "model = Model(config)\n",
        "\n",
        "optimizer = optim.Adam([{'params':model.parameters(),'lr':1e-3}])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fykMGPyCtCbF",
        "outputId": "3bc05d2b-a40c-458c-bdd2-d8722cfe95ce"
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (dense_linear): Linear(in_features=256, out_features=4, bias=True)\n",
              "  (word_embedding): Embedding(66818, 256, padding_idx=0)\n",
              "  (fastformer_model): FastformerEncoder(\n",
              "    (encoders): ModuleList(\n",
              "      (0): FastformerLayer(\n",
              "        (attention): FastAttention(\n",
              "          (self): FastSelfAttention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
              "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): FastformerLayer(\n",
              "        (attention): FastAttention(\n",
              "          (self): FastSelfAttention(\n",
              "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (query_att): Linear(in_features=256, out_features=16, bias=True)\n",
              "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (key_att): Linear(in_features=256, out_features=16, bias=True)\n",
              "            (transform): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (position_embeddings): Embedding(256, 256)\n",
              "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (poolers): ModuleList(\n",
              "      (0): AttentionPooling(\n",
              "        (att_fc1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (att_fc2): Linear(in_features=256, out_features=1, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (criterion): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyfqblqMwUTl"
      },
      "source": [
        "## training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5JcAM9stVQc",
        "outputId": "c3e4415c-ec7b-4391-80b4-37cfa363cde5"
      },
      "source": [
        "for epoch in range(2):\n",
        "    \n",
        "    loss = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    for cnt in range(len(train_index)//64):\n",
        "        \n",
        "        log_ids = news_words[train_index][cnt*64:cnt*64+64,:256]\n",
        "        targets = label[train_index][cnt*64:cnt*64+64]\n",
        "\n",
        "        log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
        "        targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
        "\n",
        "        bz_loss,y_hat = model(log_ids,targets)\n",
        "\n",
        "        loss += bz_loss.data.float()\n",
        "        accuracy += acc(targets,y_hat)\n",
        "        \n",
        "        unified_loss = bz_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        unified_loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        if cnt % 100 == 0:\n",
        "          print('Ed: {} , train_loss: {:.5f}, acc: {:.5f}'.format(cnt*64,loss.data/(cnt+1),accuracy/(cnt+1)))\n",
        "    \n",
        "    model.eval()\n",
        "    allpred = []\n",
        "\n",
        "    for cnt in range(len(test_index)//64+1):\n",
        "        \n",
        "        log_ids = news_words[test_index][cnt*64:cnt*64+64,:256]\n",
        "        targets = label[test_index][cnt*64:cnt*64+64]\n",
        "\n",
        "        log_ids = torch.LongTensor(log_ids).cuda(non_blocking=True)\n",
        "        targets = torch.LongTensor(targets).cuda(non_blocking=True)\n",
        "\n",
        "        bz_loss2, y_hat2 = model(log_ids,targets)\n",
        "\n",
        "        allpred+=y_hat2.to('cpu').detach().numpy().tolist()\n",
        "\n",
        "    \n",
        "    y_pred = np.argmax(allpred,axis=-1)\n",
        "    y_true = label[test_index]\n",
        "\n",
        "    print(accuracy_score(y_true,y_pred))\n",
        "\n",
        "    model.train()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ed: 0 , train_loss: 1.38021, acc: 0.23438\n",
            "Ed: 6400 , train_loss: 0.60755, acc: 0.77150\n",
            "Ed: 12800 , train_loss: 0.47420, acc: 0.82828\n",
            "Ed: 19200 , train_loss: 0.42214, acc: 0.84946\n",
            "Ed: 25600 , train_loss: 0.39461, acc: 0.86144\n",
            "Ed: 32000 , train_loss: 0.37150, acc: 0.87060\n",
            "Ed: 38400 , train_loss: 0.35683, acc: 0.87594\n",
            "Ed: 44800 , train_loss: 0.34549, acc: 0.88015\n",
            "Ed: 51200 , train_loss: 0.33686, acc: 0.88358\n",
            "Ed: 57600 , train_loss: 0.32772, acc: 0.88691\n",
            "Ed: 64000 , train_loss: 0.31870, acc: 0.89027\n",
            "Ed: 70400 , train_loss: 0.31294, acc: 0.89256\n",
            "Ed: 76800 , train_loss: 0.30721, acc: 0.89415\n",
            "Ed: 83200 , train_loss: 0.30279, acc: 0.89563\n",
            "Ed: 89600 , train_loss: 0.29844, acc: 0.89693\n",
            "Ed: 96000 , train_loss: 0.29450, acc: 0.89842\n",
            "Ed: 102400 , train_loss: 0.28958, acc: 0.90034\n",
            "Ed: 108800 , train_loss: 0.28550, acc: 0.90171\n",
            "Ed: 115200 , train_loss: 0.28195, acc: 0.90288\n",
            "0.9251315789473684\n",
            "Ed: 0 , train_loss: 0.30264, acc: 0.92188\n",
            "Ed: 6400 , train_loss: 0.18034, acc: 0.93905\n",
            "Ed: 12800 , train_loss: 0.16936, acc: 0.94263\n",
            "Ed: 19200 , train_loss: 0.16491, acc: 0.94316\n",
            "Ed: 25600 , train_loss: 0.16479, acc: 0.94416\n",
            "Ed: 32000 , train_loss: 0.15860, acc: 0.94642\n",
            "Ed: 38400 , train_loss: 0.15457, acc: 0.94876\n",
            "Ed: 44800 , train_loss: 0.15357, acc: 0.94878\n",
            "Ed: 51200 , train_loss: 0.15302, acc: 0.94903\n",
            "Ed: 57600 , train_loss: 0.15083, acc: 0.94974\n",
            "Ed: 64000 , train_loss: 0.14888, acc: 0.95032\n",
            "Ed: 70400 , train_loss: 0.14771, acc: 0.95061\n",
            "Ed: 76800 , train_loss: 0.14689, acc: 0.95080\n",
            "Ed: 83200 , train_loss: 0.14620, acc: 0.95059\n",
            "Ed: 89600 , train_loss: 0.14529, acc: 0.95078\n",
            "Ed: 96000 , train_loss: 0.14422, acc: 0.95099\n",
            "Ed: 102400 , train_loss: 0.14328, acc: 0.95152\n",
            "Ed: 108800 , train_loss: 0.14256, acc: 0.95177\n",
            "Ed: 115200 , train_loss: 0.14169, acc: 0.95206\n",
            "0.9238157894736843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxWNvYl5zP--"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}