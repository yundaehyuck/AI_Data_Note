{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Spacy를 이용한 영어 전처리"
      ],
      "metadata": {
        "id": "pI7QNEuYGtTo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ieASGgwiGN7S"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = nlp('Naver Connect and Upstage Boostcamp')\n",
        "\n",
        "print([token.text for token in text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1GogTSzHBca",
        "outputId": "920ac979-3cd1-4190-f839-4b9913d18825"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Naver', 'Connect', 'and', 'Upstage', 'Boostcamp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('This assignment is about Natural Language Processing.' 'In this assignment, we will do preprocessing')\n",
        "\n",
        "print([token.text for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xVWkz_rHG-3",
        "outputId": "5b4372a7-4ae2-4cbf-e865-f0859d78036a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'assignment', 'is', 'about', 'Natural', 'Language', 'Processing', '.', 'In', 'this', 'assignment', ',', 'we', 'will', 'do', 'preprocessing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = nlp(\"The film's development began when Marvel Studios received a loan from Merrill Lynch in April 2005. After the success of the film Iron Man in May 2008, \\\n",
        "Marvel announced that The Avengers would be released in July 2011 and would bring together Tony Stark, Steve Rogers, Bruce Banner, and Thor from Marvel's previous films. \\\n",
        "With the signing of Johansson as Natasha Romanoff in March 2009, the film was pushed back for a 2012 release. Whedon was brought on board in April 2010 and rewrote the original screenplay by Zak Penn. Production began in April 2011 in Albuquerque, \\\n",
        "New Mexico, before moving to Cleveland, Ohio in August and New York City in September. The film has more than 2,200 visual effects shots.\")\n",
        "\n",
        "print([token.text for token in text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxb-ltipHOBE",
        "outputId": "faa60754-e37e-4d85-8512-d2b183b9dbaa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'film', \"'s\", 'development', 'began', 'when', 'Marvel', 'Studios', 'received', 'a', 'loan', 'from', 'Merrill', 'Lynch', 'in', 'April', '2005', '.', 'After', 'the', 'success', 'of', 'the', 'film', 'Iron', 'Man', 'in', 'May', '2008', ',', 'Marvel', 'announced', 'that', 'The', 'Avengers', 'would', 'be', 'released', 'in', 'July', '2011', 'and', 'would', 'bring', 'together', 'Tony', 'Stark', ',', 'Steve', 'Rogers', ',', 'Bruce', 'Banner', ',', 'and', 'Thor', 'from', 'Marvel', \"'s\", 'previous', 'films', '.', 'With', 'the', 'signing', 'of', 'Johansson', 'as', 'Natasha', 'Romanoff', 'in', 'March', '2009', ',', 'the', 'film', 'was', 'pushed', 'back', 'for', 'a', '2012', 'release', '.', 'Whedon', 'was', 'brought', 'on', 'board', 'in', 'April', '2010', 'and', 'rewrote', 'the', 'original', 'screenplay', 'by', 'Zak', 'Penn', '.', 'Production', 'began', 'in', 'April', '2011', 'in', 'Albuquerque', ',', 'New', 'Mexico', ',', 'before', 'moving', 'to', 'Cleveland', ',', 'Ohio', 'in', 'August', 'and', 'New', 'York', 'City', 'in', 'September', '.', 'The', 'film', 'has', 'more', 'than', '2,200', 'visual', 'effects', 'shots', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2c3jhTaCHWXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 불용어 (Stopword)"
      ],
      "metadata": {
        "id": "9tVL0up5HaZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "for stop_word in list(spacy_stopwords)[:30]:\n",
        "\n",
        "    print(stop_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR-R6rmLHalp",
        "outputId": "2a1d8d26-405a-45f1-83ac-51b31100573d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "throughout\n",
            "become\n",
            "whereby\n",
            "ourselves\n",
            "fifty\n",
            "can\n",
            "per\n",
            "so\n",
            "done\n",
            "meanwhile\n",
            "seems\n",
            "see\n",
            "becoming\n",
            "get\n",
            "also\n",
            "too\n",
            "back\n",
            "both\n",
            "of\n",
            "elsewhere\n",
            "really\n",
            "have\n",
            "on\n",
            "only\n",
            "yourselves\n",
            "to\n",
            "during\n",
            "wherein\n",
            "doing\n",
            "in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exclude stopword in text\n",
        "stopword_text = [token for token in text if not token.is_stop]\n",
        "\n",
        "print(stopword_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX6B1LtdHigr",
        "outputId": "0c7bef8a-adb9-48d3-d572-c25f4a70c0ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[film, development, began, Marvel, Studios, received, loan, Merrill, Lynch, April, 2005, ., success, film, Iron, Man, 2008, ,, Marvel, announced, Avengers, released, July, 2011, bring, Tony, Stark, ,, Steve, Rogers, ,, Bruce, Banner, ,, Thor, Marvel, previous, films, ., signing, Johansson, Natasha, Romanoff, March, 2009, ,, film, pushed, 2012, release, ., Whedon, brought, board, April, 2010, rewrote, original, screenplay, Zak, Penn, ., Production, began, April, 2011, Albuquerque, ,, New, Mexico, ,, moving, Cleveland, ,, Ohio, August, New, York, City, September, ., film, 2,200, visual, effects, shots, .]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMIDFeBnHsU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Lemmatization\n",
        "\n",
        "https://4four.us/article/2008/05/lemmatization\n",
        "\n",
        "https://wikidocs.net/21707\n"
      ],
      "metadata": {
        "id": "WLkHgyChH3ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in text[:20]:\n",
        "\n",
        "    print(token, \"-\", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXIQK99CH32l",
        "outputId": "33c94422-7398-475e-dffb-ab06736a6f5e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The - the\n",
            "film - film\n",
            "'s - 's\n",
            "development - development\n",
            "began - begin\n",
            "when - when\n",
            "Marvel - Marvel\n",
            "Studios - Studios\n",
            "received - receive\n",
            "a - a\n",
            "loan - loan\n",
            "from - from\n",
            "Merrill - Merrill\n",
            "Lynch - Lynch\n",
            "in - in\n",
            "April - April\n",
            "2005 - 2005\n",
            ". - .\n",
            "After - after\n",
            "the - the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcUQbPJ4IQ86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 그외 token class의 attributes\n",
        "\n",
        "https://spacy.io/api/token#attributes"
      ],
      "metadata": {
        "id": "raJiwkj8IU4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"token \\t is_punct \\t is_space \\t shape_ \\t is_stop\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "\n",
        "for token in text[21:31]:\n",
        "\n",
        "    print(token, \"\\t\", token.is_punct, \"\\t\\t\", token.is_space, \"\\t\\t\", token.shape_, \"\\t\\t\", token.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF3plBQvIVFm",
        "outputId": "369df805-c21d-4834-894b-75d20b93ffa4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token \t is_punct \t is_space \t shape_ \t is_stop\n",
            "======================================================================\n",
            "of \t False \t\t False \t\t xx \t\t True\n",
            "the \t False \t\t False \t\t xxx \t\t True\n",
            "film \t False \t\t False \t\t xxxx \t\t False\n",
            "Iron \t False \t\t False \t\t Xxxx \t\t False\n",
            "Man \t False \t\t False \t\t Xxx \t\t False\n",
            "in \t False \t\t False \t\t xx \t\t True\n",
            "May \t False \t\t False \t\t Xxx \t\t True\n",
            "2008 \t False \t\t False \t\t dddd \t\t False\n",
            ", \t True \t\t False \t\t , \t\t False\n",
            "Marvel \t False \t\t False \t\t Xxxxx \t\t False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sgHV_Ma8Ipue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# problem"
      ],
      "metadata": {
        "id": "GqEmY-XbIu17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove stopword and punctuation\n",
        "\n",
        "def is_token_allowed(token):\n",
        "\n",
        "    if (token.is_stop) or (token.is_punct):\n",
        "\n",
        "        return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "nl_0IpIrI0go"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lemmatization\n",
        "def preprocess_token(token):\n",
        "\n",
        "    return token.lemma_.strip().lower()"
      ],
      "metadata": {
        "id": "TMUIpH_dI9DK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens = [preprocess_token(token) for token in text if is_token_allowed(token)]\n",
        "\n",
        "answer = ['film', 'development','begin', 'marvel','studios', 'receive','loan', 'merrill','lynch', 'april','2005', 'success','film', 'iron','man', '2008','marvel','announce', 'avengers','release', 'july','2011', 'bring','tony', 'stark','steve', 'rogers','bruce', 'banner','thor', 'marvel','previous', 'film','signing', 'johansson','natasha','romanoff','march','2009','film','push','2012','release','whedon','bring','board','april','2010','rewrote','original','screenplay','zak','penn','production','begin','april','2011','albuquerque','new','mexico','move','cleveland','ohio','august','new','york','city','september','film','2,200','visual','effect','shot']\n",
        "\n",
        "assert filtered_tokens == answer"
      ],
      "metadata": {
        "id": "kPl8ODROJZFv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rx1a5HdGJmAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 한국어 전처리"
      ],
      "metadata": {
        "id": "41gs_cbhJrKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Mecab를 이용한 형태소 분석 기반 토크나이징"
      ],
      "metadata": {
        "id": "gfKjj9fTJszB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install konlpy mecab in colab\n",
        "#https://somjang.tistory.com/entry/Google-Colab%EC%97%90%EC%84%9C-Mecab-koMecab-ko-dic-%EC%89%BD%EA%B2%8C-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0\n",
        "\n",
        "#NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
        "#이 셀도 다시 실행해보기\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh #install_mecab-ko_on_colab_light_xxxxxx.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLm6T7NQJrXu",
        "outputId": "71dbe43b-45c3-4243-ee0d-7b2fd9ede56f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-07-11 18:31:57--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::3403:4be7, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNFZKXRWNL&Signature=AANgWe%2Fkd5wYZei422kI0yytWr4%3D&x-amz-security-token=FwoGZXIvYXdzEFwaDPLIwhN4KMnOEk7yzyK%2BAXsQbozY%2F8UyJOb%2FOVRcHUOVXinMgThR8FQOW%2FsSeeICMzsIUKESz2krw3WEKoMD6JZSQmn297aG5ERLv3Anrz36sDba5C21mai54mybNxqAwJ0wNk9Fd8CiHfotzUq%2BTu7QbwCr%2FuRxPIvKsY7aVqgqosag%2FuklHvGihyCWZOAG7bsYBz6D69kL0G2Xa%2B51JAfHlEIhQboECQupB0eCLpLu37qsNbkqBjM%2FDWCRCOCZH5B0P5mjgMNc33AdpFkoyr%2B2pQYyLaZj7QFKRC5bKAz1hr17KKchWy0Tt9wX3AwZHyGj2fpeYLkXJqnvnsTJf5Kphg%3D%3D&Expires=1689102034 [following]\n",
            "--2023-07-11 18:31:57--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNFZKXRWNL&Signature=AANgWe%2Fkd5wYZei422kI0yytWr4%3D&x-amz-security-token=FwoGZXIvYXdzEFwaDPLIwhN4KMnOEk7yzyK%2BAXsQbozY%2F8UyJOb%2FOVRcHUOVXinMgThR8FQOW%2FsSeeICMzsIUKESz2krw3WEKoMD6JZSQmn297aG5ERLv3Anrz36sDba5C21mai54mybNxqAwJ0wNk9Fd8CiHfotzUq%2BTu7QbwCr%2FuRxPIvKsY7aVqgqosag%2FuklHvGihyCWZOAG7bsYBz6D69kL0G2Xa%2B51JAfHlEIhQboECQupB0eCLpLu37qsNbkqBjM%2FDWCRCOCZH5B0P5mjgMNc33AdpFkoyr%2B2pQYyLaZj7QFKRC5bKAz1hr17KKchWy0Tt9wX3AwZHyGj2fpeYLkXJqnvnsTJf5Kphg%3D%3D&Expires=1689102034\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.132.193, 52.216.246.84, 52.217.126.33, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.132.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.2’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.72MB/s    in 0.4s    \n",
            "\n",
            "2023-07-11 18:31:58 (3.72 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.2’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-07-11 18:32:12--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::3403:4be7, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNJZJC3DP4&Signature=JXaEh4lMmgHlJm31GTh6bJo9Ojs%3D&x-amz-security-token=FwoGZXIvYXdzEFwaDDJBEIZDMrvQDBfLuSK%2BATA%2BV%2F2Y37ZjSI42rRUXIz9ZL9%2B%2F3IxAXbVVuLBjBRCmSY3h1Oe3Rl7jwnH4hDpVI6XZNdfNdnAzYKQlBBl0r%2FuPC7oUcIvH00Yyg%2FFsqI8fhDW4V%2FquimFsDG%2FucJCabkqb0jbaTWaZZYMaixYAreO1J8NhjgyF1n94viUQPGMC36USDs7dBK8C9o7ESDeRB6SIus1wH45coV3djhyZJseyRbTFJQC86jNfWCP7pPfpzpevPBePlwHg4D%2FhKPUo37%2B2pQYyLWQeJ72qkaTTrT9JquySOgFpsJCClUCu43%2Ft0BvaeI29X%2B4dHtlAsvpYLZr5GA%3D%3D&Expires=1689102055 [following]\n",
            "--2023-07-11 18:32:12--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNJZJC3DP4&Signature=JXaEh4lMmgHlJm31GTh6bJo9Ojs%3D&x-amz-security-token=FwoGZXIvYXdzEFwaDDJBEIZDMrvQDBfLuSK%2BATA%2BV%2F2Y37ZjSI42rRUXIz9ZL9%2B%2F3IxAXbVVuLBjBRCmSY3h1Oe3Rl7jwnH4hDpVI6XZNdfNdnAzYKQlBBl0r%2FuPC7oUcIvH00Yyg%2FFsqI8fhDW4V%2FquimFsDG%2FucJCabkqb0jbaTWaZZYMaixYAreO1J8NhjgyF1n94viUQPGMC36USDs7dBK8C9o7ESDeRB6SIus1wH45coV3djhyZJseyRbTFJQC86jNfWCP7pPfpzpevPBePlwHg4D%2FhKPUo37%2B2pQYyLWQeJ72qkaTTrT9JquySOgFpsJCClUCu43%2Ft0BvaeI29X%2B4dHtlAsvpYLZr5GA%3D%3D&Expires=1689102055\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.236.67, 54.231.169.25, 52.217.125.73, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.236.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.2’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  34.8MB/s    in 1.4s    \n",
            "\n",
            "2023-07-11 18:32:14 (34.8 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.2’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n",
            "문제를 해결해주신 combacsa님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "\n",
        "import operator\n",
        "\n",
        "tokenizer = Mecab()"
      ],
      "metadata": {
        "id": "75QkvUPrJvHv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"최강의 슈퍼히어로들이 모였다! 지구의 운명을 건 거대한 전쟁이 시작된다! 지구의 안보가 위협당하는 위기의 상황에서 슈퍼히어로들을 불러모아 세상을 구하는, 일명 어벤져스 작전. 에너지원 테서랙트를 이용한 적의 등장으로 인류가 위험에 처하자 국제평화유지기구인 쉴드의 국장 닉 퓨리는 어벤져스 작전을 위해 전 세계에 흩어져 있던 슈퍼히어로들을 찾아나선다. 아이언맨부터 토르, 헐크, 캡틴 아메리카는 물론, 쉴드의 요원인 블랙 위도우, 호크아이까지, 최고의 슈퍼히어로들이 어벤져스의 멤버로 모이게 되지만, 각기 개성이 강한 이들의 만남은 예상치 못한 방향으로 흘러가는데… 지구의 운명을 건 거대한 전쟁 앞에 어벤져스 작전은 성공할 수 있을까?\""
      ],
      "metadata": {
        "id": "3v4yWQpwJ2nh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.morphs(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOSA0SXfJ64-",
        "outputId": "0b1a8f57-adbc-4680-8668-64a2797e1f93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['최강', '의', '슈퍼', '히어로', '들', '이', '모였', '다', '!', '지구', '의', '운명', '을', '건', '거대', '한', '전쟁', '이', '시작', '된다', '!', '지구', '의', '안보', '가', '위협', '당하', '는', '위기', '의', '상황', '에서', '슈퍼', '히어로', '들', '을', '불러', '모아', '세상', '을', '구하', '는', ',', '일', '명', '어벤져스', '작전', '.', '에너지원', '테', '서', '랙', '트', '를', '이용', '한', '적', '의', '등장', '으로', '인류', '가', '위험', '에', '처하', '자', '국제', '평화', '유지', '기구', '인', '쉴드', '의', '국장', '닉', '퓨리', '는', '어벤져스', '작전', '을', '위해', '전', '세계', '에', '흩어져', '있', '던', '슈퍼', '히어로', '들', '을', '찾', '아', '나선다', '.', '아이언맨', '부터', '토르', ',', '헐크', ',', '캡틴', '아메리카', '는', '물론', ',', '쉴드', '의', '요원', '인', '블랙', '위', '도우', ',', '호크아이', '까지', ',', '최고', '의', '슈퍼', '히어로', '들', '이', '어벤져스', '의', '멤버', '로', '모이', '게', '되', '지만', ',', '각기', '개성', '이', '강한', '이', '들', '의', '만남', '은', '예상', '치', '못한', '방향', '으로', '흘러가', '는데', '…', '지구', '의', '운명', '을', '건', '거대', '한', '전쟁', '앞', '에', '어벤져스', '작전', '은', '성공', '할', '수', '있', '을까', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting stopwords\n",
        "\n",
        "stopwords = ['의','가','이','은','다','들','을',\n",
        "             '는','인','위해','과','던','도','를','로',\n",
        "             '게','으로','까지','자','에','을까','는데',\n",
        "             '치','와','한','하다']"
      ],
      "metadata": {
        "id": "2nMDudnpJ-V8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exclude stopword\n",
        "tokenized_text = [word for word in tokenizer.morphs(text) if not word in stopwords]\n",
        "\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BQCJA44KEaN",
        "outputId": "05a77ad0-007c-44b6-c302-4164b0ab22b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['최강', '슈퍼', '히어로', '모였', '!', '지구', '운명', '건', '거대', '전쟁', '시작', '된다', '!', '지구', '안보', '위협', '당하', '위기', '상황', '에서', '슈퍼', '히어로', '불러', '모아', '세상', '구하', ',', '일', '명', '어벤져스', '작전', '.', '에너지원', '테', '서', '랙', '트', '이용', '적', '등장', '인류', '위험', '처하', '국제', '평화', '유지', '기구', '쉴드', '국장', '닉', '퓨리', '어벤져스', '작전', '전', '세계', '흩어져', '있', '슈퍼', '히어로', '찾', '아', '나선다', '.', '아이언맨', '부터', '토르', ',', '헐크', ',', '캡틴', '아메리카', '물론', ',', '쉴드', '요원', '블랙', '위', '도우', ',', '호크아이', ',', '최고', '슈퍼', '히어로', '어벤져스', '멤버', '모이', '되', '지만', ',', '각기', '개성', '강한', '만남', '예상', '못한', '방향', '흘러가', '…', '지구', '운명', '건', '거대', '전쟁', '앞', '어벤져스', '작전', '성공', '할', '수', '있', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 음절 단위 토크나이징 실습"
      ],
      "metadata": {
        "id": "rU7bttLAKQxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "starry_night=['계절이 지나가는 하늘에는',\n",
        "'가을로 가득 차 있습니다.',\n",
        "'나는 아무 걱정도 없이',\n",
        "'가을 속의 별들을 다 헬 듯합니다.',\n",
        "'가슴 속에 하나 둘 새겨지는 별을',\n",
        "'이제 다 못 헤는 것은',\n",
        "'쉬이 아침이 오는 까닭이요,',\n",
        "'내일 밤이 남은 까닭이요,',\n",
        "'아직 나의 청춘이 다하지 않은 까닭입니다.',\n",
        "'별 하나에 추억과',\n",
        "'별 하나에 사랑과',\n",
        "'별 하나에 쓸쓸함과',\n",
        "'별 하나에 동경과',\n",
        "'별 하나에 시와',\n",
        "'별 하나에 어머니, 어머니,',\n",
        "\"어머님, 나는 별 하나에 아름다운 말 한마디씩 불러 봅니다. 소학교 때 책상을 같이 했던 아이들의 이름과, 패, 경, 옥, 이런 이국 소녀들의 이름과, 벌써 아기 어머니 된 계집애들의 이름과, 가난한 이웃 사람들의 이름과, 비둘기, 강아지, 토끼, 노새, 노루, '프랑시스 잠', '라이너 마리아 릴케’ 이런 시인의 이름을 불러 봅니다.\",\n",
        "'이네들은 너무나 멀리 있습니다.',\n",
        "'별이 아스라이 멀듯이.',\n",
        "'어머님,',\n",
        "'그리고 당신은 멀리 북간도에 계십니다.',\n",
        "'나는 무엇인지 그리워',\n",
        "'이 많은 별빛이 내린 언덕 위에',\n",
        "'내 이름자를 써 보고',\n",
        "'흙으로 덮어 버리었습니다.',\n",
        "'딴은 밤을 새워 우는 벌레는',\n",
        "'부끄러운 이름을 슬퍼하는 까닭입니다.',\n",
        "'그러나 겨울이 지나고 나의 별에도 봄이 오면',\n",
        "'무덤 위에 파란 잔디가 피어나듯이',\n",
        "'내 이름자 묻힌 언덕 위에도',\n",
        "'자랑처럼 풀이 무성할 거외다.',]"
      ],
      "metadata": {
        "id": "tRZ5lSErKSIj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = []\n",
        "\n",
        "for sentence in starry_night:\n",
        "\n",
        "    tokenized_text = [token for token in sentence]\n",
        "\n",
        "    tokens.extend(tokenized_text)"
      ],
      "metadata": {
        "id": "xOqBRkbTKUTe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS2reN5GOtYs",
        "outputId": "05be204b-786c-4ddc-b26b-6e3bea182fd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['계', '절', '이', ' ', '지', '나', '가', '는', ' ', '하', '늘', '에', '는', '가', '을', '로', ' ', '가', '득', ' ', '차', ' ', '있', '습', '니', '다', '.', '나', '는', ' ', '아', '무', ' ', '걱', '정', '도', ' ', '없', '이', '가', '을', ' ', '속', '의', ' ', '별', '들', '을', ' ', '다', ' ', '헬', ' ', '듯', '합', '니', '다', '.', '가', '슴', ' ', '속', '에', ' ', '하', '나', ' ', '둘', ' ', '새', '겨', '지', '는', ' ', '별', '을', '이', '제', ' ', '다', ' ', '못', ' ', '헤', '는', ' ', '것', '은', '쉬', '이', ' ', '아', '침', '이', ' ', '오', '는', ' ', '까', '닭', '이', '요', ',', '내', '일', ' ', '밤', '이', ' ', '남', '은', ' ', '까', '닭', '이', '요', ',', '아', '직', ' ', '나', '의', ' ', '청', '춘', '이', ' ', '다', '하', '지', ' ', '않', '은', ' ', '까', '닭', '입', '니', '다', '.', '별', ' ', '하', '나', '에', ' ', '추', '억', '과', '별', ' ', '하', '나', '에', ' ', '사', '랑', '과', '별', ' ', '하', '나', '에', ' ', '쓸', '쓸', '함', '과', '별', ' ', '하', '나', '에', ' ', '동', '경', '과', '별', ' ', '하', '나', '에', ' ', '시', '와', '별', ' ', '하', '나', '에', ' ', '어', '머', '니', ',', ' ', '어', '머', '니', ',', '어', '머', '님', ',', ' ', '나', '는', ' ', '별', ' ', '하', '나', '에', ' ', '아', '름', '다', '운', ' ', '말', ' ', '한', '마', '디', '씩', ' ', '불', '러', ' ', '봅', '니', '다', '.', ' ', '소', '학', '교', ' ', '때', ' ', '책', '상', '을', ' ', '같', '이', ' ', '했', '던', ' ', '아', '이', '들', '의', ' ', '이', '름', '과', ',', ' ', '패', ',', ' ', '경', ',', ' ', '옥', ',', ' ', '이', '런', ' ', '이', '국', ' ', '소', '녀', '들', '의', ' ', '이', '름', '과', ',', ' ', '벌', '써', ' ', '아', '기', ' ', '어', '머', '니', ' ', '된', ' ', '계', '집', '애', '들', '의', ' ', '이', '름', '과', ',', ' ', '가', '난', '한', ' ', '이', '웃', ' ', '사', '람', '들', '의', ' ', '이', '름', '과', ',', ' ', '비', '둘', '기', ',', ' ', '강', '아', '지', ',', ' ', '토', '끼', ',', ' ', '노', '새', ',', ' ', '노', '루', ',', ' ', \"'\", '프', '랑', '시', '스', ' ', '잠', \"'\", ',', ' ', \"'\", '라', '이', '너', ' ', '마', '리', '아', ' ', '릴', '케', '’', ' ', '이', '런', ' ', '시', '인', '의', ' ', '이', '름', '을', ' ', '불', '러', ' ', '봅', '니', '다', '.', '이', '네', '들', '은', ' ', '너', '무', '나', ' ', '멀', '리', ' ', '있', '습', '니', '다', '.', '별', '이', ' ', '아', '스', '라', '이', ' ', '멀', '듯', '이', '.', '어', '머', '님', ',', '그', '리', '고', ' ', '당', '신', '은', ' ', '멀', '리', ' ', '북', '간', '도', '에', ' ', '계', '십', '니', '다', '.', '나', '는', ' ', '무', '엇', '인', '지', ' ', '그', '리', '워', '이', ' ', '많', '은', ' ', '별', '빛', '이', ' ', '내', '린', ' ', '언', '덕', ' ', '위', '에', '내', ' ', '이', '름', '자', '를', ' ', '써', ' ', '보', '고', '흙', '으', '로', ' ', '덮', '어', ' ', '버', '리', '었', '습', '니', '다', '.', '딴', '은', ' ', '밤', '을', ' ', '새', '워', ' ', '우', '는', ' ', '벌', '레', '는', '부', '끄', '러', '운', ' ', '이', '름', '을', ' ', '슬', '퍼', '하', '는', ' ', '까', '닭', '입', '니', '다', '.', '그', '러', '나', ' ', '겨', '울', '이', ' ', '지', '나', '고', ' ', '나', '의', ' ', '별', '에', '도', ' ', '봄', '이', ' ', '오', '면', '무', '덤', ' ', '위', '에', ' ', '파', '란', ' ', '잔', '디', '가', ' ', '피', '어', '나', '듯', '이', '내', ' ', '이', '름', '자', ' ', '묻', '힌', ' ', '언', '덕', ' ', '위', '에', '도', '자', '랑', '처', '럼', ' ', '풀', '이', ' ', '무', '성', '할', ' ', '거', '외', '다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## problem"
      ],
      "metadata": {
        "id": "kN7hiE68Kfew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict = {}\n",
        "\n",
        "for token in tokens:\n",
        "\n",
        "    #make vocab_dict\n",
        "    #key: token, value: count\n",
        "    #example: vocab_dict={\"나\":3,\"그\":5,\"어\":3,...}\n",
        "\n",
        "    vocab_dict[token] = vocab_dict.get(token,0) + 1\n",
        ""
      ],
      "metadata": {
        "id": "r6QuYr3FKhpz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_vocab = sorted(vocab_dict.items(), key = operator.itemgetter(1), reverse=True)"
      ],
      "metadata": {
        "id": "WTVITUD5Oy8o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = []\n",
        "\n",
        "for token, freq in sorted_vocab:\n",
        "\n",
        "    #find token that has count more than two, append vocab list\n",
        "\n",
        "    if freq >= 2:\n",
        "\n",
        "        vocab.append(token)"
      ],
      "metadata": {
        "id": "xRjwkGsiO4lk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer=[' ','이',',','나','에','다','니','별','는', '하', '.', '아', '름', '을', '의', '과', '가', '은', '어', '지', '들', '리', '무', '머', '도', '까', '닭', '내', '러', '계', '습', '듯', '새', '랑', '시', \"'\", '멀', '그', '고', '위', '자', '로', '있', '속', '둘', '겨', '오', '요', '밤', '입', '사', '쓸', '경', '님', '운', '한', '마', '디', '불', '봅', '소', '런', '벌', '써', '기', '노', '스', '라', '너', '인', '워', '언', '덕']\n",
        "\n",
        "assert vocab == answer"
      ],
      "metadata": {
        "id": "01UWnQxjPMVm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r7-CH-R6PR-T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}