{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **1. NaiveBayes Classifier**\n",
        "1. 주어진 데이터를 전처리합니다.\n",
        "2. NaiveBayes 분류기 모델을 구현하고 학습 데이터로 이를 학습시킵니다.\n",
        "3. 간단한 test case로 결과를 확인합니다."
      ],
      "metadata": {
        "id": "lMQhT2CNPkJu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJMcqD1u9xfe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **필요 패키지 import**"
      ],
      "metadata": {
        "id": "-uvRz_v8PnYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "id": "PHb4Viy4PnxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "#다양한 한국어 형태소 분석기가 클래스로 구현되어 있음\n",
        "from konlpy import tag\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import math"
      ],
      "metadata": {
        "id": "BQFwJlBXPphM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g1-k8k6ZQk0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **학습 및 테스트 데이터 전처리**"
      ],
      "metadata": {
        "id": "0VTqXvwdQnae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample 데이터를 확인합니다.  \n",
        "긍정($1$), 부정($0$) 2가지 class로 구성되어 있습니다."
      ],
      "metadata": {
        "id": "cMsZQiPLQpW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [\n",
        "  \"정말 맛있습니다. 추천합니다.\",\n",
        "  \"기대했던 것보단 별로였네요.\",\n",
        "  \"다 좋은데 가격이 너무 비싸서 다시 가고 싶다는 생각이 안 드네요.\",\n",
        "  \"완전 최고입니다! 재방문 의사 있습니다.\",\n",
        "  \"음식도 서비스도 다 만족스러웠습니다.\",\n",
        "  \"위생 상태가 좀 별로였습니다. 좀 더 개선되기를 바랍니다.\",\n",
        "  \"맛도 좋았고 직원분들 서비스도 너무 친절했습니다.\",\n",
        "  \"기념일에 방문했는데 음식도 분위기도 서비스도 다 좋았습니다.\",\n",
        "  \"전반적으로 음식이 너무 짰습니다. 저는 별로였네요.\",\n",
        "  \"위생에 조금 더 신경 썼으면 좋겠습니다. 조금 불쾌했습니다.\"\n",
        "]\n",
        "train_labels = [1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
        "\n",
        "test_data = [\n",
        "  \"정말 좋았습니다. 또 가고 싶네요.\",\n",
        "  \"별로였습니다. 되도록 가지 마세요.\",\n",
        "  \"다른 분들께도 추천드릴 수 있을 만큼 만족했습니다.\",\n",
        "  \"서비스가 좀 더 개선되었으면 좋겠습니다. 기분이 좀 나빴습니다.\"\n",
        "]"
      ],
      "metadata": {
        "id": "piMzKT8MQnpp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EjMiAmxJQsdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KoNLPy 패키지에서 제공하는 Twitter(Okt) tokenizer를 사용하여 tokenization합니다."
      ],
      "metadata": {
        "id": "-0T7eqKxQwTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tag.Okt()"
      ],
      "metadata": {
        "id": "Zt-_gI_rQwnz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tokenized(data):\n",
        "\n",
        "    tokenized = [] #단어 단위로 나뉜 리뷰 데이터\n",
        "\n",
        "    for sent in tqdm(data):\n",
        "\n",
        "        tokens = tokenizer.morphs(sent) #'string'으로 구성된 sentence를\n",
        "        tokenized.append(tokens) #token으로 구성된 리스트를 반환\n",
        "\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "X34OQNFDQyMG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenized = make_tokenized(train_data)\n",
        "\n",
        "test_tokenized = make_tokenized(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uf5RlV8RCjx",
        "outputId": "66876031-a95f-4654-eb30-dca4952c954b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
            "100%|██████████| 4/4 [00:00<00:00, 67.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZFbxhOVRInE",
        "outputId": "4b5fab84-7e8b-40b3-aa89-afc496843226"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['정말', '맛있습니다', '.', '추천', '합니다', '.'],\n",
              " ['기대했던', '것', '보단', '별로', '였네요', '.'],\n",
              " ['다',\n",
              "  '좋은데',\n",
              "  '가격',\n",
              "  '이',\n",
              "  '너무',\n",
              "  '비싸서',\n",
              "  '다시',\n",
              "  '가고',\n",
              "  '싶다는',\n",
              "  '생각',\n",
              "  '이',\n",
              "  '안',\n",
              "  '드네',\n",
              "  '요',\n",
              "  '.'],\n",
              " ['완전', '최고', '입니다', '!', '재', '방문', '의사', '있습니다', '.'],\n",
              " ['음식', '도', '서비스', '도', '다', '만족스러웠습니다', '.'],\n",
              " ['위생',\n",
              "  '상태',\n",
              "  '가',\n",
              "  '좀',\n",
              "  '별로',\n",
              "  '였습니다',\n",
              "  '.',\n",
              "  '좀',\n",
              "  '더',\n",
              "  '개선',\n",
              "  '되',\n",
              "  '기를',\n",
              "  '바랍니다',\n",
              "  '.'],\n",
              " ['맛', '도', '좋았고', '직원', '분들', '서비스', '도', '너무', '친절했습니다', '.'],\n",
              " ['기념일',\n",
              "  '에',\n",
              "  '방문',\n",
              "  '했는데',\n",
              "  '음식',\n",
              "  '도',\n",
              "  '분위기',\n",
              "  '도',\n",
              "  '서비스',\n",
              "  '도',\n",
              "  '다',\n",
              "  '좋았습니다',\n",
              "  '.'],\n",
              " ['전반', '적', '으로', '음식', '이', '너무', '짰습니다', '.', '저', '는', '별로', '였네요', '.'],\n",
              " ['위생', '에', '조금', '더', '신경', '썼으면', '좋겠습니다', '.', '조금', '불쾌했습니다', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lZlccjjPRjon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습데이터 기준으로 가장 많이 등장한 단어부터 순서대로 vocab에 추가합니다."
      ],
      "metadata": {
        "id": "rS9xP69iRncX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_count = defaultdict(int) #key: 단어, value: 등장 횟수\n",
        "\n",
        "for tokens in tqdm(train_tokenized):\n",
        "\n",
        "    for token in tokens:\n",
        "\n",
        "        word_count[token] += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIcPQsNLRnpY",
        "outputId": "db27cda1-866a-475c-c2b6-9326d4efa77b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 39681.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lambda에 의해 count 기반의 sort\n",
        "#reverse로 내림차순 정렬\n",
        "word_count = sorted(word_count.items(), key = lambda x: x[1], reverse=True)\n",
        "\n",
        "#vocab은 실전에서는 사이즈가 엄청 크다\n",
        "print(len(word_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqsH-7NORxI3",
        "outputId": "a7e37af0-060a-48c5-e1c8-96ce533f6c30"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2i = {} #key : 단어, value: 단어의 index\n",
        "\n",
        "for pair in tqdm(word_count):\n",
        "\n",
        "    if pair[0] not in w2i:\n",
        "\n",
        "        w2i[pair[0]] = len(w2i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqufQ1P7R3ic",
        "outputId": "546886a4-3f50-4af3-aa2c-a14361f738a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 66/66 [00:00<00:00, 272196.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(w2i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0aJSfyGSMft",
        "outputId": "9e07218f-bd6a-41d1-f873-1669990be8ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKZmC5phSOa2",
        "outputId": "1f0149be-3e28-4193-c3b4-4387c7bc0920"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 0,\n",
              " '도': 1,\n",
              " '별로': 2,\n",
              " '다': 3,\n",
              " '이': 4,\n",
              " '너무': 5,\n",
              " '음식': 6,\n",
              " '서비스': 7,\n",
              " '였네요': 8,\n",
              " '방문': 9,\n",
              " '위생': 10,\n",
              " '좀': 11,\n",
              " '더': 12,\n",
              " '에': 13,\n",
              " '조금': 14,\n",
              " '정말': 15,\n",
              " '맛있습니다': 16,\n",
              " '추천': 17,\n",
              " '합니다': 18,\n",
              " '기대했던': 19,\n",
              " '것': 20,\n",
              " '보단': 21,\n",
              " '좋은데': 22,\n",
              " '가격': 23,\n",
              " '비싸서': 24,\n",
              " '다시': 25,\n",
              " '가고': 26,\n",
              " '싶다는': 27,\n",
              " '생각': 28,\n",
              " '안': 29,\n",
              " '드네': 30,\n",
              " '요': 31,\n",
              " '완전': 32,\n",
              " '최고': 33,\n",
              " '입니다': 34,\n",
              " '!': 35,\n",
              " '재': 36,\n",
              " '의사': 37,\n",
              " '있습니다': 38,\n",
              " '만족스러웠습니다': 39,\n",
              " '상태': 40,\n",
              " '가': 41,\n",
              " '였습니다': 42,\n",
              " '개선': 43,\n",
              " '되': 44,\n",
              " '기를': 45,\n",
              " '바랍니다': 46,\n",
              " '맛': 47,\n",
              " '좋았고': 48,\n",
              " '직원': 49,\n",
              " '분들': 50,\n",
              " '친절했습니다': 51,\n",
              " '기념일': 52,\n",
              " '했는데': 53,\n",
              " '분위기': 54,\n",
              " '좋았습니다': 55,\n",
              " '전반': 56,\n",
              " '적': 57,\n",
              " '으로': 58,\n",
              " '짰습니다': 59,\n",
              " '저': 60,\n",
              " '는': 61,\n",
              " '신경': 62,\n",
              " '썼으면': 63,\n",
              " '좋겠습니다': 64,\n",
              " '불쾌했습니다': 65}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GdvEY0YkSO9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **모델 Class 구현**"
      ],
      "metadata": {
        "id": "n-qR7keNSRkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NaiveBayes Classifier 모델 클래스를 구현합니다.\n",
        "\n",
        "*   `self.k`: Smoothing을 위한 상수.\n",
        "*   `self.w2i`: 사전에 구한 vocab.\n",
        "*   `self.priors`: 각 class의 prior 확률.\n",
        "*   `self.likelihoods`: 각 token의 특정 class 조건 내에서의 likelihood."
      ],
      "metadata": {
        "id": "FdNIZ4CKSUqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier():\n",
        "\n",
        "    def __init__(self, w2i, k = 0.1):\n",
        "\n",
        "        self.k = k\n",
        "        self.w2i = w2i\n",
        "        self.priors = {}\n",
        "        self.likelihoods = {}\n",
        "\n",
        "    def train(self, train_tokenized, train_labels):\n",
        "\n",
        "        self.set_priors(train_labels) #prior 계산\n",
        "        self.set_likelihoods(train_tokenized, train_labels) #likelihoods 계산\n",
        "\n",
        "    def inference(self, tokens): #test할때 사용\n",
        "\n",
        "        #p = likelihood * prior\n",
        "        #logp = log(likelihood) + log(prior)\n",
        "        #logp = sum(log(pi)) + log(prior)\n",
        "\n",
        "        log_prob0 = 0.0\n",
        "        log_prob1 = 0.0\n",
        "\n",
        "        for token in tokens:\n",
        "\n",
        "            if token in self.likelihoods: #학습 당시 추가했던 단어에 대해서만 고려한다\n",
        "\n",
        "                #log를 사용하는 이유는 거듭적으로 곱하면 0으로 수렴하기때문에 로그로 바꿔서 합으로 바꾸기 위해\n",
        "                log_prob0 += math.log(self.likelihoods[token][0])\n",
        "                log_prob1 += math.log(self.likelihoods[token][1])\n",
        "\n",
        "        #마지막에 prior 고려\n",
        "\n",
        "        log_prob0 += math.log(self.priors[0])\n",
        "        log_prob1 += math.log(self.priors[1])\n",
        "\n",
        "        if log_prob0 >= log_prob1:\n",
        "\n",
        "            return 0\n",
        "\n",
        "        else:\n",
        "\n",
        "            return 1\n",
        "\n",
        "    def set_priors(self, train_labels):\n",
        "\n",
        "        class_counts = defaultdict(int)\n",
        "\n",
        "        for label in tqdm(train_labels):\n",
        "\n",
        "            class_counts[label] += 1\n",
        "\n",
        "        for label, count in class_counts.items():\n",
        "\n",
        "            self.priors[label] = class_counts[label] / len(train_labels)\n",
        "\n",
        "    def set_likelihoods(self, train_tokenized, train_labels):\n",
        "\n",
        "        token_dicts = {} #각 단어의 특정 class 조건 하에서의 등장 횟수\n",
        "\n",
        "        class_counts = defaultdict(int) #특정 class에서 등장한 모든 단어의 등장 횟수\n",
        "\n",
        "        for i, label in enumerate(tqdm(train_labels)):\n",
        "\n",
        "            count = 0\n",
        "\n",
        "            for token in train_tokenized[i]:\n",
        "\n",
        "                if token in self.w2i: #학습 데이터로 구축한 vocab에 있는 token만 고려함\n",
        "\n",
        "                    if token not in token_dicts:\n",
        "\n",
        "                        token_dicts[token] = {0:0, 1:1}\n",
        "\n",
        "                    token_dicts[token][label] += 1\n",
        "                    count += 1\n",
        "\n",
        "            class_counts[label] += count\n",
        "\n",
        "        for token,dist in tqdm(token_dicts.items()):\n",
        "\n",
        "            if token not in self.likelihoods:\n",
        "\n",
        "                self.likelihoods[token] = {\n",
        "                    0:(token_dicts[token][0] + self.k) / (class_counts[0] + len(self.w2i) * self.k),\n",
        "                    1:(token_dicts[token][1] + self.k) / (class_counts[1] + len(self.w2i) * self.k)\n",
        "                }"
      ],
      "metadata": {
        "id": "OlXc--d2SS_8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TgvfRF3JUjlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **모델 학습**"
      ],
      "metadata": {
        "id": "9uybNGdIVjjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 객체를 만들고 학습 데이터로 학습시킵니다."
      ],
      "metadata": {
        "id": "-OWyNYfqVlHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier(w2i)\n",
        "classifier.train(train_tokenized, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcuX34k6Vju6",
        "outputId": "fd393f0c-87cf-488c-f347-9c1bd139fde9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 80043.97it/s]\n",
            "100%|██████████| 10/10 [00:00<00:00, 39089.51it/s]\n",
            "100%|██████████| 66/66 [00:00<00:00, 273271.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hf3I_SLdVrl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **테스트**"
      ],
      "metadata": {
        "id": "EFZ98aHdVyP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test sample에 대한 결과는 다음과 같습니다."
      ],
      "metadata": {
        "id": "qcRtLL7mVz9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "\n",
        "for test_tokens in tqdm(test_tokenized):\n",
        "\n",
        "    pred = classifier.inference(test_tokens)\n",
        "    preds.append(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqGILPFzVycX",
        "outputId": "1e887946-6911-4c12-e173-476fe275cdcb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 5976.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l024Ky0XV7IX",
        "outputId": "47c93f80-546e-4be2-ba5a-b252df17f490"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_-hU-TUJV79u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}